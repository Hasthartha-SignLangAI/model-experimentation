{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1. Setup & Extract Zip"
      ],
      "metadata": {
        "id": "4LvUYgYKeHve"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IAVn4mUJdvnf",
        "outputId": "2e5056be-5669-4fdb-e10b-bea2a501d8ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted contents:\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "# ===========================\n",
        "# 1. BASIC SETUP & ZIP EXTRACT\n",
        "# ===========================\n",
        "import os\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import joblib\n",
        "\n",
        "# For reproducibility\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "# ---- CONFIG: EDIT THESE IF NEEDED ----\n",
        "DATASET_ZIP = \"/content/v2.zip\"  # <- name of your uploaded zip\n",
        "EXTRACT_DIR = \"/content\"         # where to extract\n",
        "DATASET_DIR  = os.path.join(EXTRACT_DIR, \"v2\")  # root of v2 data\n",
        "\n",
        "# If your zip structure is different, print after extract and adjust DATASET_DIR\n",
        "\n",
        "# ---- Extract zip (run once per Colab session) ----\n",
        "if not os.path.exists(EXTRACT_DIR):\n",
        "    os.makedirs(EXTRACT_DIR, exist_ok=True)\n",
        "\n",
        "with zipfile.ZipFile(DATASET_ZIP, \"r\") as z:\n",
        "    z.extractall(EXTRACT_DIR)\n",
        "\n",
        "print(\"Extracted contents:\")\n",
        "for root, dirs, files in os.walk(EXTRACT_DIR):\n",
        "    print(root)\n",
        "    # only show first level or two\n",
        "    break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Data Loading Helpers"
      ],
      "metadata": {
        "id": "Zr_PPBXaeLcc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# 2. DATA LOADING FUNCTIONS\n",
        "# ===========================\n",
        "\n",
        "# column names in each txt file\n",
        "COLS = [\"t\", \"emg1\", \"emg2\", \"emg3\", \"ax\", \"ay\", \"az\", \"gx\", \"gy\", \"gz\"]\n",
        "FEATURE_COLS = [\"emg1\", \"emg2\", \"emg3\", \"ax\", \"ay\", \"az\", \"gx\", \"gy\", \"gz\"]\n",
        "\n",
        "def load_sensor_file(path):\n",
        "    \"\"\"\n",
        "    Load a single .txt file into a DataFrame.\n",
        "    Handles files without headers: comma-separated numeric values.\n",
        "    \"\"\"\n",
        "    # robust reading (if there are any weird bytes, latin-1 won't crash)\n",
        "    df = pd.read_csv(\n",
        "        path,\n",
        "        header=None,\n",
        "        names=COLS,\n",
        "        encoding=\"latin-1\",\n",
        "        on_bad_lines='skip' # Added to skip lines with too many columns\n",
        "    )\n",
        "\n",
        "    # drop completely empty rows (if any)\n",
        "    df = df.dropna(how=\"all\")\n",
        "\n",
        "    # keep only numeric columns, coerce errors\n",
        "    for c in COLS:\n",
        "        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
        "    df = df.dropna().reset_index(drop=True)\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def load_dataset(dataset_dir):\n",
        "    \"\"\"\n",
        "    Walks dataset_dir and loads all gesture samples.\n",
        "    Assumes:\n",
        "        dataset_dir / <gesture_name> / Day_* / *.txt\n",
        "    Returns:\n",
        "        X_raw: list of (Ti, num_features) numpy arrays\n",
        "        y_raw: list of gesture labels (strings)\n",
        "        gesture_list: sorted list of unique gesture names\n",
        "    \"\"\"\n",
        "    X_raw = []\n",
        "    y_raw = []\n",
        "\n",
        "    # gesture folders (e.g. ada, awidinawa, boru, ...)\n",
        "    gesture_dirs = sorted([\n",
        "        d for d in os.listdir(dataset_dir)\n",
        "        if os.path.isdir(os.path.join(dataset_dir, d))\n",
        "    ])\n",
        "\n",
        "    print(\"Found gesture folders:\", gesture_dirs)\n",
        "\n",
        "    for gesture in gesture_dirs:\n",
        "        g_path = os.path.join(dataset_dir, gesture)\n",
        "\n",
        "        # inside each gesture, expect Day_1, Day_2, ... or txts directly\n",
        "        # handle both patterns\n",
        "        subdirs = [\n",
        "            os.path.join(g_path, d) for d in os.listdir(g_path)\n",
        "            if os.path.isdir(os.path.join(g_path, d))\n",
        "        ]\n",
        "        txt_files = [\n",
        "            os.path.join(g_path, f) for f in os.listdir(g_path)\n",
        "            if f.endswith(\".txt\")\n",
        "        ]\n",
        "\n",
        "        # case 1: Day subfolders\n",
        "        if subdirs:\n",
        "            for day_dir in sorted(subdirs):\n",
        "                for fname in sorted(os.listdir(day_dir)):\n",
        "                    if not fname.endswith(\".txt\"):\n",
        "                        continue\n",
        "                    fpath = os.path.join(day_dir, fname)\n",
        "                    df = load_sensor_file(fpath)\n",
        "                    if len(df) == 0:\n",
        "                        continue\n",
        "                    X_raw.append(df[FEATURE_COLS].values)\n",
        "                    y_raw.append(gesture)\n",
        "        # case 2: txt files directly in gesture folder\n",
        "        if txt_files:\n",
        "            for fpath in sorted(txt_files):\n",
        "                df = load_sensor_file(fpath)\n",
        "                if len(df) == 0:\n",
        "                    continue\n",
        "                X_raw.append(df[FEATURE_COLS].values)\n",
        "                y_raw.append(gesture)\n",
        "\n",
        "    gesture_list = sorted(list(set(y_raw)))\n",
        "    return X_raw, y_raw, gesture_list\n",
        "\n",
        "\n",
        "# ---- Load everything ----\n",
        "X_raw, y_raw, gesture_list = load_dataset(DATASET_DIR)\n",
        "print(\"Total samples:\", len(X_raw))\n",
        "print(\"Classes:\", gesture_list)\n",
        "\n",
        "# Quick check of sequence lengths\n",
        "lengths = [x.shape[0] for x in X_raw]\n",
        "print(\"Min len:\", min(lengths), \"Max len:\", max(lengths), \"Median:\", int(np.median(lengths)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0YsXTaAeO2c",
        "outputId": "b43a5421-94c2-4d6a-fa7f-8c714df41675"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found gesture folders: ['ada', 'awidinawa', 'boru', 'hawasa', 'hodai', 'irida', 'narakai', 'pata', 'saduda', 'udasana']\n",
            "Total samples: 1000\n",
            "Classes: ['ada', 'awidinawa', 'boru', 'hawasa', 'hodai', 'irida', 'narakai', 'pata', 'saduda', 'udasana']\n",
            "Min len: 400 Max len: 1070 Median: 680\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Preprocessing: Normalization + Padding"
      ],
      "metadata": {
        "id": "YCKuicgteR-J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# 3. PREPROCESSING\n",
        "# ===========================\n",
        "\n",
        "MAX_LEN = 600  # you can tune this (e.g. 512, 800, ...)\n",
        "\n",
        "num_features = len(FEATURE_COLS)\n",
        "\n",
        "# --- 3.1 Fit scaler on all data (stack all frames) ---\n",
        "all_frames = np.vstack(X_raw)  # (total_frames, num_features)\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(all_frames)\n",
        "print(\"Scaler fitted on frames:\", all_frames.shape)\n",
        "\n",
        "# --- 3.2 Helper to scale + pad/truncate ---\n",
        "def preprocess_sequence(seq):\n",
        "    \"\"\"\n",
        "    seq: (T, num_features)\n",
        "    returns: (MAX_LEN, num_features) float32\n",
        "    \"\"\"\n",
        "    seq_scaled = scaler.transform(seq)\n",
        "\n",
        "    if len(seq_scaled) > MAX_LEN:\n",
        "        seq_scaled = seq_scaled[:MAX_LEN]\n",
        "    else:\n",
        "        pad_len = MAX_LEN - len(seq_scaled)\n",
        "        pad = np.zeros((pad_len, num_features), dtype=np.float32)\n",
        "        seq_scaled = np.vstack([seq_scaled, pad])\n",
        "\n",
        "    return seq_scaled.astype(np.float32)\n",
        "\n",
        "\n",
        "# --- 3.3 Encode labels ---\n",
        "label_to_idx = {label: i for i, label in enumerate(gesture_list)}\n",
        "idx_to_label = {i: l for l, i in label_to_idx.items()}\n",
        "print(\"Label map:\", label_to_idx)\n",
        "\n",
        "# --- 3.4 Apply preprocessing to all samples ---\n",
        "X = np.stack([preprocess_sequence(seq) for seq in X_raw])  # (N, MAX_LEN, num_features)\n",
        "y = np.array([label_to_idx[l] for l in y_raw], dtype=np.int64)\n",
        "\n",
        "print(\"X shape:\", X.shape, \"y shape:\", y.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q4TL1EqbeVuA",
        "outputId": "407da1ec-efaf-49eb-8950-e23e05edadeb"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scaler fitted on frames: (690989, 9)\n",
            "Label map: {'ada': 0, 'awidinawa': 1, 'boru': 2, 'hawasa': 3, 'hodai': 4, 'irida': 5, 'narakai': 6, 'pata': 7, 'saduda': 8, 'udasana': 9}\n",
            "X shape: (1000, 600, 9) y shape: (1000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Train / Val / Test Split"
      ],
      "metadata": {
        "id": "cIVMYUrmebwg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# 4. TRAIN / VAL / TEST SPLIT\n",
        "# ===========================\n",
        "test_size = 0.15\n",
        "val_size = 0.15  # of remaining train\n",
        "\n",
        "X_trainval, X_test, y_trainval, y_test = train_test_split(\n",
        "    X, y, test_size=test_size, random_state=SEED, stratify=y\n",
        ")\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_trainval, y_trainval, test_size=val_size, random_state=SEED, stratify=y_trainval\n",
        ")\n",
        "\n",
        "print(\"Train:\", X_train.shape, \"Val:\", X_val.shape, \"Test:\", X_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lU29S6-becym",
        "outputId": "060490d1-9844-43ff-fb96-7d5bfdf3911b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: (722, 600, 9) Val: (128, 600, 9) Test: (150, 600, 9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. CNN + LSTM Model"
      ],
      "metadata": {
        "id": "M6meZq6Mefoo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# 5. BUILD CNN + LSTM MODEL\n",
        "# ===========================\n",
        "num_classes = len(gesture_list)\n",
        "\n",
        "def build_cnn_lstm_model(max_len, num_features, num_classes):\n",
        "    inputs = layers.Input(shape=(max_len, num_features))\n",
        "\n",
        "    x = layers.Conv1D(64, kernel_size=5, padding=\"same\", activation=\"relu\")(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.MaxPooling1D(pool_size=2)(x)\n",
        "\n",
        "    x = layers.Conv1D(128, kernel_size=5, padding=\"same\", activation=\"relu\")(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.MaxPooling1D(pool_size=2)(x)\n",
        "\n",
        "    x = layers.Conv1D(128, kernel_size=3, padding=\"same\", activation=\"relu\")(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.MaxPooling1D(pool_size=2)(x)\n",
        "\n",
        "    x = layers.Bidirectional(layers.LSTM(64, return_sequences=False))(x)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "\n",
        "    x = layers.Dense(64, activation=\"relu\")(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "\n",
        "    outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
        "\n",
        "    model = models.Model(inputs=inputs, outputs=outputs)\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "        loss=\"sparse_categorical_crossentropy\",\n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "    return model\n",
        "\n",
        "model = build_cnn_lstm_model(MAX_LEN, num_features, num_classes)\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "id": "8iZxleLbeiKF",
        "outputId": "25475f32-c069-4933-ce9d-9b0ac3e6dafc"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m600\u001b[0m, \u001b[38;5;34m9\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m600\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │         \u001b[38;5;34m2,944\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m600\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m41,088\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m49,280\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_2 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m98,816\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,944</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">41,088</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,280</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m202,314\u001b[0m (790.29 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">202,314</span> (790.29 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m201,674\u001b[0m (787.79 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">201,674</span> (787.79 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m640\u001b[0m (2.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> (2.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Train With Callbacks"
      ],
      "metadata": {
        "id": "B--_jJmKelI-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# 6. TRAINING\n",
        "# ===========================\n",
        "batch_size = 32\n",
        "epochs = 50\n",
        "\n",
        "early_stop = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor=\"val_loss\",\n",
        "    patience=8,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor=\"val_loss\",\n",
        "    factor=0.5,\n",
        "    patience=4,\n",
        "    min_lr=1e-5,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=epochs,\n",
        "    batch_size=batch_size,\n",
        "    callbacks=[early_stop, reduce_lr],\n",
        "    verbose=1\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ija4PMp8eoVZ",
        "outputId": "5f9559b4-73f2-40f6-bdb1-1e2132baba04"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 273ms/step - accuracy: 0.1584 - loss: 2.3067 - val_accuracy: 0.2578 - val_loss: 2.2188 - learning_rate: 0.0010\n",
            "Epoch 2/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 328ms/step - accuracy: 0.3169 - loss: 1.8822 - val_accuracy: 0.2969 - val_loss: 2.0933 - learning_rate: 0.0010\n",
            "Epoch 3/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 244ms/step - accuracy: 0.3973 - loss: 1.6761 - val_accuracy: 0.3594 - val_loss: 1.9942 - learning_rate: 0.0010\n",
            "Epoch 4/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 290ms/step - accuracy: 0.4565 - loss: 1.5287 - val_accuracy: 0.3359 - val_loss: 1.8528 - learning_rate: 0.0010\n",
            "Epoch 5/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 252ms/step - accuracy: 0.5245 - loss: 1.4131 - val_accuracy: 0.4062 - val_loss: 1.7198 - learning_rate: 0.0010\n",
            "Epoch 6/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 328ms/step - accuracy: 0.5315 - loss: 1.2794 - val_accuracy: 0.4297 - val_loss: 1.5039 - learning_rate: 0.0010\n",
            "Epoch 7/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 243ms/step - accuracy: 0.5769 - loss: 1.1647 - val_accuracy: 0.5000 - val_loss: 1.3386 - learning_rate: 0.0010\n",
            "Epoch 8/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 275ms/step - accuracy: 0.6637 - loss: 0.9886 - val_accuracy: 0.5781 - val_loss: 1.2093 - learning_rate: 0.0010\n",
            "Epoch 9/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 243ms/step - accuracy: 0.6660 - loss: 0.9262 - val_accuracy: 0.6797 - val_loss: 0.8920 - learning_rate: 0.0010\n",
            "Epoch 10/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 301ms/step - accuracy: 0.7244 - loss: 0.7628 - val_accuracy: 0.7500 - val_loss: 0.7309 - learning_rate: 0.0010\n",
            "Epoch 11/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 245ms/step - accuracy: 0.7940 - loss: 0.6057 - val_accuracy: 0.7812 - val_loss: 0.5851 - learning_rate: 0.0010\n",
            "Epoch 12/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 303ms/step - accuracy: 0.8366 - loss: 0.5018 - val_accuracy: 0.8672 - val_loss: 0.4352 - learning_rate: 0.0010\n",
            "Epoch 13/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 247ms/step - accuracy: 0.8856 - loss: 0.4127 - val_accuracy: 0.8750 - val_loss: 0.3567 - learning_rate: 0.0010\n",
            "Epoch 14/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 242ms/step - accuracy: 0.9027 - loss: 0.2925 - val_accuracy: 0.9062 - val_loss: 0.3071 - learning_rate: 0.0010\n",
            "Epoch 15/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 285ms/step - accuracy: 0.9225 - loss: 0.2628 - val_accuracy: 0.8906 - val_loss: 0.3271 - learning_rate: 0.0010\n",
            "Epoch 16/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 253ms/step - accuracy: 0.9179 - loss: 0.2913 - val_accuracy: 0.8750 - val_loss: 0.3439 - learning_rate: 0.0010\n",
            "Epoch 17/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 268ms/step - accuracy: 0.9131 - loss: 0.2552 - val_accuracy: 0.8906 - val_loss: 0.2603 - learning_rate: 0.0010\n",
            "Epoch 18/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 242ms/step - accuracy: 0.9537 - loss: 0.1606 - val_accuracy: 0.9453 - val_loss: 0.1699 - learning_rate: 0.0010\n",
            "Epoch 19/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 301ms/step - accuracy: 0.9536 - loss: 0.1405 - val_accuracy: 0.9688 - val_loss: 0.0876 - learning_rate: 0.0010\n",
            "Epoch 20/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 270ms/step - accuracy: 0.9694 - loss: 0.1077 - val_accuracy: 0.9766 - val_loss: 0.0959 - learning_rate: 0.0010\n",
            "Epoch 21/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 239ms/step - accuracy: 0.9822 - loss: 0.0899 - val_accuracy: 0.9688 - val_loss: 0.0945 - learning_rate: 0.0010\n",
            "Epoch 22/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 246ms/step - accuracy: 0.9913 - loss: 0.0563 - val_accuracy: 0.9766 - val_loss: 0.0776 - learning_rate: 0.0010\n",
            "Epoch 23/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 243ms/step - accuracy: 0.9820 - loss: 0.0752 - val_accuracy: 0.9844 - val_loss: 0.0517 - learning_rate: 0.0010\n",
            "Epoch 24/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 291ms/step - accuracy: 0.9848 - loss: 0.0756 - val_accuracy: 0.9531 - val_loss: 0.0846 - learning_rate: 0.0010\n",
            "Epoch 25/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 244ms/step - accuracy: 0.9836 - loss: 0.0711 - val_accuracy: 0.9375 - val_loss: 0.1103 - learning_rate: 0.0010\n",
            "Epoch 26/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 300ms/step - accuracy: 0.9869 - loss: 0.0558 - val_accuracy: 0.9766 - val_loss: 0.0857 - learning_rate: 0.0010\n",
            "Epoch 27/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - accuracy: 0.9923 - loss: 0.0316\n",
            "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 239ms/step - accuracy: 0.9923 - loss: 0.0316 - val_accuracy: 0.9609 - val_loss: 0.1295 - learning_rate: 0.0010\n",
            "Epoch 28/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 244ms/step - accuracy: 0.9931 - loss: 0.0333 - val_accuracy: 0.9766 - val_loss: 0.0963 - learning_rate: 5.0000e-04\n",
            "Epoch 29/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 304ms/step - accuracy: 0.9922 - loss: 0.0230 - val_accuracy: 0.9844 - val_loss: 0.0939 - learning_rate: 5.0000e-04\n",
            "Epoch 30/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 242ms/step - accuracy: 0.9940 - loss: 0.0226 - val_accuracy: 0.9844 - val_loss: 0.0838 - learning_rate: 5.0000e-04\n",
            "Epoch 31/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 287ms/step - accuracy: 0.9973 - loss: 0.0190\n",
            "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 303ms/step - accuracy: 0.9973 - loss: 0.0190 - val_accuracy: 0.9844 - val_loss: 0.0702 - learning_rate: 5.0000e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Evaluation on Test Set"
      ],
      "metadata": {
        "id": "TfhOjUu9erGv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# 7. EVALUATION\n",
        "# ===========================\n",
        "\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Test accuracy: {test_acc:.4f}, Test loss: {test_loss:.4f}\")\n",
        "\n",
        "# Detailed report\n",
        "y_pred_probs = model.predict(X_test)\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=gesture_list))\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmYTv-VUetYk",
        "outputId": "06e6a3c4-5379-4020-b2f0-8eb2c98c04df"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.9333, Test loss: 0.2012\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 379ms/step\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ada       0.93      0.87      0.90        15\n",
            "   awidinawa       0.93      0.93      0.93        15\n",
            "        boru       0.93      0.93      0.93        15\n",
            "      hawasa       1.00      0.87      0.93        15\n",
            "       hodai       0.88      1.00      0.94        15\n",
            "       irida       0.83      1.00      0.91        15\n",
            "     narakai       1.00      0.87      0.93        15\n",
            "        pata       1.00      1.00      1.00        15\n",
            "      saduda       1.00      0.93      0.97        15\n",
            "     udasana       0.88      0.93      0.90        15\n",
            "\n",
            "    accuracy                           0.93       150\n",
            "   macro avg       0.94      0.93      0.93       150\n",
            "weighted avg       0.94      0.93      0.93       150\n",
            "\n",
            "Confusion Matrix:\n",
            "[[13  0  0  0  1  1  0  0  0  0]\n",
            " [ 1 14  0  0  0  0  0  0  0  0]\n",
            " [ 0  0 14  0  1  0  0  0  0  0]\n",
            " [ 0  0  0 13  0  0  0  0  0  2]\n",
            " [ 0  0  0  0 15  0  0  0  0  0]\n",
            " [ 0  0  0  0  0 15  0  0  0  0]\n",
            " [ 0  1  0  0  0  1 13  0  0  0]\n",
            " [ 0  0  0  0  0  0  0 15  0  0]\n",
            " [ 0  0  1  0  0  0  0  0 14  0]\n",
            " [ 0  0  0  0  0  1  0  0  0 14]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. Save Model, Scaler, and Label Map"
      ],
      "metadata": {
        "id": "4yDDWrlzevin"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# 8. SAVE ARTIFACTS\n",
        "# ===========================\n",
        "MODEL_PATH = \"/content/gesture_model_v2.h5\"\n",
        "SCALER_PATH = \"/content/scaler_v2.pkl\"\n",
        "LABEL_MAP_PATH = \"/content/label_map_v2.pkl\"\n",
        "\n",
        "model.save(MODEL_PATH)\n",
        "joblib.dump(scaler, SCALER_PATH)\n",
        "joblib.dump(label_to_idx, LABEL_MAP_PATH)\n",
        "\n",
        "print(\"Saved model to:\", MODEL_PATH)\n",
        "print(\"Saved scaler to:\", SCALER_PATH)\n",
        "print(\"Saved label map to:\", LABEL_MAP_PATH)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "-0frFF7yezHw",
        "outputId": "a36dfa29-992a-43d3-8fe5-67dc2c61ebe4"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved model to: /content/gesture_model_v2.h5\n",
            "Saved scaler to: /content/scaler_v2.pkl\n",
            "Saved label map to: /content/label_map_v2.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(MODEL_PATH)\n",
        "files.download(SCALER_PATH)\n",
        "files.download(LABEL_MAP_PATH)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "X_FsVC8Be4JA",
        "outputId": "1b6233e0-1ead-4eaa-b3ef-2fd69286c56b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_5ca86ce4-136f-4389-b3df-96079024bb2b\", \"gesture_model_v2.h5\", 2514336)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_b94458f1-1a8a-49ba-9947-022165018fff\", \"scaler_v2.pkl\", 815)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_554d2f92-d6a3-4eff-be46-0f4d39ad6b9e\", \"label_map_v2.pkl\", 122)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}
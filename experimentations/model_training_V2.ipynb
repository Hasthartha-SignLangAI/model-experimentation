{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import zipfile, os\n",
        "\n",
        "ZIP_NAME = \"Dataset_V2.zip\"  # must match the uploaded filename\n",
        "\n",
        "with zipfile.ZipFile(ZIP_NAME, 'r') as z:\n",
        "    z.extractall(\"/content\")\n",
        "\n",
        "print(\"Extracted folders in /content:\")\n",
        "print([p for p in os.listdir(\"/content\") if \"Dataset\" in p or \"dataset\" in p])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RB90i9iiiFvS",
        "outputId": "9d3f4783-833a-4219-c2b8-54a0f73e8081"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted folders in /content:\n",
            "['Dataset_V2', 'Dataset_V2.zip']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CYqU-h3TfzRp",
        "outputId": "e39f2b38-8a60-4ee9-87df-d7e335bc40bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded: (1100, 512, 9) classes: 11 skipped: 0\n",
            "Label map: {'idle': 0, 'ada': 1, 'awidinawa': 2, 'boru': 3, 'hawasa': 4, 'hodai': 5, 'irida': 6, 'narakai': 7, 'pata': 8, 'saduda': 9, 'udasana': 10}\n",
            "Days present: ['Day_1', 'Day_10', 'Day_2', 'Day_3', 'Day_4', 'Day_5', 'Day_6', 'Day_7', 'Day_8', 'Day_9']\n",
            "Train samples: 881\n",
            "Val samples: 110\n",
            "Test samples: 109\n",
            "Class weights: {0: 1.0011363636363637, 1: 1.0011363636363637, 2: 1.0011363636363637, 3: 0.9887766554433222, 4: 1.0011363636363637, 5: 1.0011363636363637, 6: 1.0011363636363637, 7: 1.0011363636363637, 8: 1.0011363636363637, 9: 1.0011363636363637, 10: 1.0011363636363637}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m9\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │         \u001b[38;5;34m2,944\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ re_lu (\u001b[38;5;33mReLU\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m24,704\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ re_lu_1 (\u001b[38;5;33mReLU\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m131,584\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m16,512\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m)             │         \u001b[38;5;34m1,419\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,944</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ re_lu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ re_lu_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,419</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m177,931\u001b[0m (695.04 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">177,931</span> (695.04 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m177,547\u001b[0m (693.54 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">177,547</span> (693.54 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m384\u001b[0m (1.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> (1.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/60\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 308ms/step - accuracy: 0.1558 - loss: 2.3717 - val_accuracy: 0.2182 - val_loss: 2.2220 - learning_rate: 0.0010\n",
            "Epoch 2/60\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 332ms/step - accuracy: 0.2863 - loss: 1.9798 - val_accuracy: 0.2545 - val_loss: 1.9526 - learning_rate: 0.0010\n",
            "Epoch 3/60\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 328ms/step - accuracy: 0.4129 - loss: 1.6992 - val_accuracy: 0.4818 - val_loss: 1.5477 - learning_rate: 0.0010\n",
            "Epoch 4/60\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 279ms/step - accuracy: 0.4667 - loss: 1.4167 - val_accuracy: 0.3091 - val_loss: 1.8101 - learning_rate: 0.0010\n",
            "Epoch 5/60\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 342ms/step - accuracy: 0.4829 - loss: 1.3382 - val_accuracy: 0.5545 - val_loss: 1.0685 - learning_rate: 0.0010\n",
            "Epoch 6/60\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 328ms/step - accuracy: 0.5566 - loss: 1.1713 - val_accuracy: 0.6273 - val_loss: 1.0258 - learning_rate: 0.0010\n",
            "Epoch 7/60\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 276ms/step - accuracy: 0.6372 - loss: 0.9604 - val_accuracy: 0.5909 - val_loss: 0.9800 - learning_rate: 0.0010\n",
            "Epoch 8/60\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 329ms/step - accuracy: 0.6543 - loss: 0.9305 - val_accuracy: 0.5909 - val_loss: 0.9553 - learning_rate: 0.0010\n",
            "Epoch 9/60\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 327ms/step - accuracy: 0.7060 - loss: 0.7557 - val_accuracy: 0.6909 - val_loss: 0.8652 - learning_rate: 0.0010\n",
            "Epoch 10/60\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 275ms/step - accuracy: 0.7578 - loss: 0.6606 - val_accuracy: 0.7273 - val_loss: 0.7582 - learning_rate: 0.0010\n",
            "Epoch 11/60\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 345ms/step - accuracy: 0.8075 - loss: 0.5637 - val_accuracy: 0.7455 - val_loss: 0.6660 - learning_rate: 0.0010\n",
            "Epoch 12/60\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 333ms/step - accuracy: 0.8228 - loss: 0.5157 - val_accuracy: 0.7091 - val_loss: 0.7696 - learning_rate: 0.0010\n",
            "Epoch 13/60\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 312ms/step - accuracy: 0.8138 - loss: 0.5031 - val_accuracy: 0.6909 - val_loss: 0.7788 - learning_rate: 0.0010\n",
            "Epoch 14/60\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 280ms/step - accuracy: 0.8263 - loss: 0.4563 - val_accuracy: 0.8636 - val_loss: 0.5150 - learning_rate: 0.0010\n",
            "Epoch 15/60\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 328ms/step - accuracy: 0.8711 - loss: 0.4342 - val_accuracy: 0.7000 - val_loss: 0.9352 - learning_rate: 0.0010\n",
            "Epoch 16/60\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 326ms/step - accuracy: 0.8964 - loss: 0.3935 - val_accuracy: 0.8818 - val_loss: 0.3394 - learning_rate: 0.0010\n",
            "Epoch 17/60\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 284ms/step - accuracy: 0.8792 - loss: 0.3553 - val_accuracy: 0.8545 - val_loss: 0.3838 - learning_rate: 0.0010\n",
            "Epoch 18/60\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 307ms/step - accuracy: 0.8823 - loss: 0.3256 - val_accuracy: 0.8091 - val_loss: 0.4252 - learning_rate: 0.0010\n",
            "Epoch 19/60\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 326ms/step - accuracy: 0.9423 - loss: 0.1997 - val_accuracy: 0.8455 - val_loss: 0.4362 - learning_rate: 0.0010\n",
            "Epoch 20/60\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 319ms/step - accuracy: 0.9537 - loss: 0.1549 - val_accuracy: 0.9364 - val_loss: 0.2897 - learning_rate: 0.0010\n",
            "Epoch 21/60\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 278ms/step - accuracy: 0.9617 - loss: 0.1071 - val_accuracy: 0.9455 - val_loss: 0.2202 - learning_rate: 0.0010\n",
            "Epoch 22/60\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 329ms/step - accuracy: 0.9513 - loss: 0.1297 - val_accuracy: 0.9273 - val_loss: 0.2718 - learning_rate: 0.0010\n",
            "Epoch 23/60\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 328ms/step - accuracy: 0.9713 - loss: 0.0989 - val_accuracy: 0.9636 - val_loss: 0.1342 - learning_rate: 0.0010\n",
            "Epoch 24/60\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 276ms/step - accuracy: 0.9850 - loss: 0.0805 - val_accuracy: 0.9636 - val_loss: 0.2199 - learning_rate: 0.0010\n",
            "Epoch 25/60\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 324ms/step - accuracy: 0.9680 - loss: 0.1412 - val_accuracy: 0.8727 - val_loss: 0.5283 - learning_rate: 0.0010\n",
            "Epoch 26/60\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 337ms/step - accuracy: 0.9748 - loss: 0.0818 - val_accuracy: 0.9455 - val_loss: 0.2380 - learning_rate: 0.0010\n",
            "Epoch 27/60\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 284ms/step - accuracy: 0.9850 - loss: 0.0598 - val_accuracy: 0.9091 - val_loss: 0.4869 - learning_rate: 0.0010\n",
            "Epoch 28/60\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 307ms/step - accuracy: 0.9687 - loss: 0.0976 - val_accuracy: 0.9455 - val_loss: 0.2606 - learning_rate: 0.0010\n",
            "Epoch 29/60\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 326ms/step - accuracy: 0.9857 - loss: 0.0536 - val_accuracy: 0.9545 - val_loss: 0.2293 - learning_rate: 5.0000e-04\n",
            "Epoch 30/60\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 287ms/step - accuracy: 0.9732 - loss: 0.1251 - val_accuracy: 0.9091 - val_loss: 0.2806 - learning_rate: 5.0000e-04\n",
            "Epoch 31/60\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 311ms/step - accuracy: 0.9818 - loss: 0.0603 - val_accuracy: 0.9364 - val_loss: 0.2951 - learning_rate: 5.0000e-04\n",
            "Epoch 32/60\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 329ms/step - accuracy: 0.9945 - loss: 0.0272 - val_accuracy: 0.9455 - val_loss: 0.2519 - learning_rate: 5.0000e-04\n",
            "Epoch 33/60\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 295ms/step - accuracy: 0.9900 - loss: 0.0350 - val_accuracy: 0.9364 - val_loss: 0.2701 - learning_rate: 5.0000e-04\n",
            "✅ Test accuracy (Day_1–8 → Day_10): 0.8899082541465759\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=h5\n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        idle     0.7692    1.0000    0.8696        10\n",
            "         ada     1.0000    0.4000    0.5714        10\n",
            "   awidinawa     0.6154    0.8000    0.6957        10\n",
            "        boru     1.0000    1.0000    1.0000        10\n",
            "      hawasa     0.9000    0.9000    0.9000        10\n",
            "       hodai     1.0000    1.0000    1.0000        10\n",
            "       irida     1.0000    0.8889    0.9412         9\n",
            "     narakai     0.9091    1.0000    0.9524        10\n",
            "        pata     0.9091    1.0000    0.9524        10\n",
            "      saduda     0.9000    0.9000    0.9000        10\n",
            "     udasana     1.0000    0.9000    0.9474        10\n",
            "\n",
            "    accuracy                         0.8899       109\n",
            "   macro avg     0.9093    0.8899    0.8845       109\n",
            "weighted avg     0.9085    0.8899    0.8840       109\n",
            "\n",
            "\n",
            "Confusion matrix (rows=true, cols=pred):\n",
            "[[10  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 2  4  4  0  0  0  0  0  0  0  0]\n",
            " [ 1  0  8  0  0  0  0  1  0  0  0]\n",
            " [ 0  0  0 10  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  9  0  0  0  0  1  0]\n",
            " [ 0  0  0  0  0 10  0  0  0  0  0]\n",
            " [ 0  0  1  0  0  0  8  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0 10  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0 10  0  0]\n",
            " [ 0  0  0  0  1  0  0  0  0  9  0]\n",
            " [ 0  0  0  0  0  0  0  0  1  0  9]]\n",
            "Saved cnn_lstm_with_idle.h5\n",
            "Saved label_map.json and scaler_params.json\n",
            "Saved artifact at '/content/cnn_lstm_with_idle_savedmodel'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 512, 9), dtype=tf.float32, name='keras_tensor')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 11), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  139529648753360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139527058315344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139527058317264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139527058314192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139527058314960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139527058318224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139527058318416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139527058318608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139527058316496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139527058317840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139527058317072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139527058318992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139527058320912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139527058321296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139527058322448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139527058321104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139527058321488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139527058322256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139527058323600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "Saved SavedModel to /content/cnn_lstm_with_idle_savedmodel\n",
            "  adding: content/cnn_lstm_with_idle_savedmodel/ (stored 0%)\n",
            "  adding: content/cnn_lstm_with_idle_savedmodel/saved_model.pb (deflated 86%)\n",
            "  adding: content/cnn_lstm_with_idle_savedmodel/variables/ (stored 0%)\n",
            "  adding: content/cnn_lstm_with_idle_savedmodel/variables/variables.data-00000-of-00001 (deflated 8%)\n",
            "  adding: content/cnn_lstm_with_idle_savedmodel/variables/variables.index (deflated 68%)\n",
            "  adding: content/cnn_lstm_with_idle_savedmodel/assets/ (stored 0%)\n",
            "  adding: content/cnn_lstm_with_idle_savedmodel/fingerprint.pb (stored 0%)\n"
          ]
        }
      ],
      "source": [
        "import os, glob, json\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# =======================\n",
        "# CONFIG\n",
        "# =======================\n",
        "DATASET_ROOT = \"Dataset_V2\"\n",
        "\n",
        "T = 512\n",
        "SEED = 42\n",
        "EPOCHS = 60\n",
        "BATCH = 32\n",
        "LR = 1e-3\n",
        "\n",
        "tf.random.set_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "\n",
        "# =======================\n",
        "# Robust reader\n",
        "# =======================\n",
        "def load_csv_robust(fp, expected_cols=10):\n",
        "    with open(fp, \"rb\") as f:\n",
        "        raw = f.read().replace(b\"\\x00\", b\"\")\n",
        "    text = raw.decode(\"utf-8\", errors=\"ignore\")\n",
        "\n",
        "    good_rows = []\n",
        "    for line in text.splitlines():\n",
        "        line = line.strip()\n",
        "        if not line:\n",
        "            continue\n",
        "        while line.endswith(\",\"):\n",
        "            line = line[:-1].strip()\n",
        "        parts = [p.strip() for p in line.split(\",\")]\n",
        "        if len(parts) != expected_cols:\n",
        "            continue\n",
        "        if any(p == \"\" for p in parts):\n",
        "            continue\n",
        "        try:\n",
        "            good_rows.append([float(p) for p in parts])\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "    if not good_rows:\n",
        "        raise ValueError(f\"No valid numeric rows in {fp}\")\n",
        "    return np.array(good_rows, dtype=np.float32)\n",
        "\n",
        "# =======================\n",
        "# Cropping (Option 2)\n",
        "# =======================\n",
        "def moving_average(x, w=25):\n",
        "    w = max(1, int(w))\n",
        "    kernel = np.ones(w, dtype=np.float32) / w\n",
        "    return np.convolve(x, kernel, mode=\"same\")\n",
        "\n",
        "def fix_length_center(X, target_len):\n",
        "    if len(X) >= target_len:\n",
        "        start = (len(X) - target_len) // 2\n",
        "        return X[start:start + target_len]\n",
        "    pad = np.zeros((target_len - len(X), X.shape[1]), dtype=X.dtype)\n",
        "    return np.vstack([X, pad])\n",
        "\n",
        "def emg_dc_remove(X):\n",
        "    X = X.copy()\n",
        "    X[:, :3] -= X[:, :3].mean(axis=0, keepdims=True)\n",
        "    return X\n",
        "\n",
        "def crop_active_region_emg(X, target_len=512, smooth_w=25, thresh_ratio=0.25):\n",
        "    Traw = X.shape[0]\n",
        "    if Traw == 0:\n",
        "        return np.zeros((target_len, X.shape[1]), dtype=np.float32)\n",
        "\n",
        "    energy = np.sum(np.abs(X[:, :3]), axis=1)\n",
        "    energy_s = moving_average(energy, w=smooth_w)\n",
        "\n",
        "    mx = float(np.max(energy_s))\n",
        "    if mx <= 1e-6:\n",
        "        return fix_length_center(X, target_len)\n",
        "\n",
        "    thresh = thresh_ratio * mx\n",
        "    active = np.where(energy_s >= thresh)[0]\n",
        "    if len(active) < 5:\n",
        "        return fix_length_center(X, target_len)\n",
        "\n",
        "    start = int(active[0])\n",
        "    end   = int(active[-1])\n",
        "    center = (start + end) // 2\n",
        "\n",
        "    half = target_len // 2\n",
        "    win_start = max(0, center - half)\n",
        "    win_end = win_start + target_len\n",
        "    if win_end > Traw:\n",
        "        win_end = Traw\n",
        "        win_start = max(0, win_end - target_len)\n",
        "\n",
        "    cropped = X[win_start:win_end]\n",
        "    if cropped.shape[0] < target_len:\n",
        "        pad = np.zeros((target_len - cropped.shape[0], X.shape[1]), dtype=cropped.dtype)\n",
        "        cropped = np.vstack([cropped, pad])\n",
        "    return cropped\n",
        "\n",
        "# =======================\n",
        "# Dataset loading with DAY metadata (Option A: include IDLE)\n",
        "# =======================\n",
        "def build_label_map(root):\n",
        "    labels = sorted([d for d in os.listdir(root) if os.path.isdir(os.path.join(root, d))])\n",
        "\n",
        "    # ✅ Force idle to index 0 if present\n",
        "    if \"idle\" in labels:\n",
        "        labels.remove(\"idle\")\n",
        "        labels = [\"idle\"] + labels\n",
        "\n",
        "    return {lbl: i for i, lbl in enumerate(labels)}\n",
        "\n",
        "def load_one_sample(path, is_idle=False):\n",
        "    arr = load_csv_robust(path, expected_cols=10)    # (Traw, 10)\n",
        "    X = arr[:, 1:]                                   # drop timestamp -> (Traw, 9)\n",
        "    X = emg_dc_remove(X)\n",
        "\n",
        "    # ✅ Key change: idle should NOT be \"active-cropped\"\n",
        "    if is_idle:\n",
        "        X = fix_length_center(X, T)\n",
        "    else:\n",
        "        X = crop_active_region_emg(X, target_len=T, smooth_w=25, thresh_ratio=0.25)\n",
        "\n",
        "    return X.astype(np.float32)\n",
        "\n",
        "def load_dataset_with_days(root):\n",
        "    label2id = build_label_map(root)\n",
        "    X_list, y_list, day_list = [], [], []\n",
        "    skipped = 0\n",
        "\n",
        "    for label, lab_id in label2id.items():\n",
        "        class_dir = os.path.join(root, label)\n",
        "        files = sorted(glob.glob(os.path.join(class_dir, \"**\", \"*.txt\"), recursive=True))\n",
        "\n",
        "        for fp in files:\n",
        "            day_name = os.path.basename(os.path.dirname(fp))  # parent folder: Day_1, Day_2...\n",
        "            try:\n",
        "                X = load_one_sample(fp, is_idle=(label == \"idle\"))\n",
        "                X_list.append(X)\n",
        "                y_list.append(lab_id)\n",
        "                day_list.append(day_name)\n",
        "            except:\n",
        "                skipped += 1\n",
        "                # print(\"[SKIP]\", fp)\n",
        "                pass\n",
        "\n",
        "    X_all = np.stack(X_list, axis=0)  # (N, T, 9)\n",
        "    y_all = np.array(y_list, dtype=np.int64)\n",
        "    days  = np.array(day_list)\n",
        "\n",
        "    print(\"Loaded:\", X_all.shape, \"classes:\", len(label2id), \"skipped:\", skipped)\n",
        "    print(\"Label map:\", label2id)\n",
        "    print(\"Days present:\", sorted(set(days.tolist())))\n",
        "    return X_all, y_all, days, label2id\n",
        "\n",
        "def normalize_train_only(X_train, X_val, X_test):\n",
        "    N, TT, F = X_train.shape\n",
        "    scaler = StandardScaler()\n",
        "    scaler.fit(X_train.reshape(-1, F))\n",
        "\n",
        "    X_train = scaler.transform(X_train.reshape(-1, F)).reshape(N, TT, F)\n",
        "    X_val   = scaler.transform(X_val.reshape(-1, F)).reshape(X_val.shape[0], TT, F)\n",
        "    X_test  = scaler.transform(X_test.reshape(-1, F)).reshape(X_test.shape[0], TT, F)\n",
        "\n",
        "    return X_train, X_val, X_test, scaler\n",
        "\n",
        "# =======================\n",
        "# Model\n",
        "# =======================\n",
        "def build_cnn_lstm(T, F, num_classes):\n",
        "    inp = layers.Input(shape=(T, F))\n",
        "\n",
        "    x = layers.Conv1D(64, 5, padding=\"same\")(inp)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "    x = layers.MaxPool1D(2)(x)\n",
        "\n",
        "    x = layers.Conv1D(128, 3, padding=\"same\")(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "    x = layers.MaxPool1D(2)(x)\n",
        "\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "    x = layers.LSTM(128)(x)\n",
        "    x = layers.Dropout(0.4)(x)\n",
        "\n",
        "    x = layers.Dense(128, activation=\"relu\")(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "\n",
        "    out = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
        "\n",
        "    model = models.Model(inp, out)\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(LR),\n",
        "        loss=\"sparse_categorical_crossentropy\",\n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "    return model\n",
        "\n",
        "def evaluate(model, X_test, y_test, id2label):\n",
        "    pred = model.predict(X_test, verbose=0).argmax(axis=1)\n",
        "    print(\"\\nClassification report:\")\n",
        "    print(classification_report(\n",
        "        y_test, pred,\n",
        "        target_names=[id2label[i] for i in range(len(id2label))],\n",
        "        digits=4\n",
        "    ))\n",
        "    cm = confusion_matrix(y_test, pred)\n",
        "    print(\"\\nConfusion matrix (rows=true, cols=pred):\")\n",
        "    print(cm)\n",
        "\n",
        "# =======================\n",
        "# RUN: Day-wise split (same as yours)\n",
        "# =======================\n",
        "X, y, days, label2id = load_dataset_with_days(DATASET_ROOT)\n",
        "id2label = {v:k for k,v in label2id.items()}\n",
        "\n",
        "TRAIN_DAYS = {f\"Day_{i}\" for i in range(1, 9)}   # Day_1..Day_8\n",
        "VAL_DAYS   = {\"Day_9\"}\n",
        "TEST_DAYS  = {\"Day_10\"}\n",
        "\n",
        "train_mask = np.isin(days, list(TRAIN_DAYS))\n",
        "val_mask   = np.isin(days, list(VAL_DAYS))\n",
        "test_mask  = np.isin(days, list(TEST_DAYS))\n",
        "\n",
        "print(\"Train samples:\", train_mask.sum())\n",
        "print(\"Val samples:\", val_mask.sum())\n",
        "print(\"Test samples:\", test_mask.sum())\n",
        "\n",
        "X_train, y_train = X[train_mask], y[train_mask]\n",
        "X_val,   y_val   = X[val_mask],   y[val_mask]\n",
        "X_test,  y_test  = X[test_mask],  y[test_mask]\n",
        "\n",
        "# Normalize\n",
        "X_train, X_val, X_test, scaler = normalize_train_only(X_train, X_val, X_test)\n",
        "\n",
        "# ✅ Recommended: class weights (prevents “always idle” collapse)\n",
        "classes = np.unique(y_train)\n",
        "weights = compute_class_weight(class_weight=\"balanced\", classes=classes, y=y_train)\n",
        "class_weight = {int(c): float(w) for c, w in zip(classes, weights)}\n",
        "print(\"Class weights:\", class_weight)\n",
        "\n",
        "model = build_cnn_lstm(T, X_train.shape[-1], len(label2id))\n",
        "model.summary()\n",
        "\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\", patience=10, restore_best_weights=True),\n",
        "    tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=5, min_lr=1e-6),\n",
        "]\n",
        "\n",
        "model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=EPOCHS,\n",
        "    batch_size=BATCH,\n",
        "    shuffle=True,\n",
        "    callbacks=callbacks,\n",
        "    class_weight=class_weight,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"✅ Test accuracy (Day_1–8 → Day_10):\", acc)\n",
        "\n",
        "evaluate(model, X_test, y_test, id2label)\n",
        "\n",
        "# =======================\n",
        "# SAVE ARTIFACTS (Updated names)\n",
        "# =======================\n",
        "# 1) H5 (optional)\n",
        "model.save(\"cnn_lstm_with_idle.h5\", save_format=\"h5\")\n",
        "print(\"Saved cnn_lstm_with_idle.h5\")\n",
        "\n",
        "# 2) Label map\n",
        "with open(\"label_map.json\", \"w\") as f:\n",
        "    json.dump(label2id, f, indent=2)\n",
        "\n",
        "# 3) Scaler params\n",
        "scaler_params = {\n",
        "    \"mean\": scaler.mean_.tolist(),\n",
        "    \"scale\": scaler.scale_.tolist()\n",
        "}\n",
        "with open(\"scaler_params.json\", \"w\") as f:\n",
        "    json.dump(scaler_params, f, indent=2)\n",
        "\n",
        "print(\"Saved label_map.json and scaler_params.json\")\n",
        "\n",
        "# 4) SavedModel (recommended for realtime)\n",
        "SAVE_DIR = \"/content/cnn_lstm_with_idle_savedmodel\"\n",
        "model.export(SAVE_DIR)\n",
        "print(\"Saved SavedModel to\", SAVE_DIR)\n",
        "\n",
        "# Zip it for download\n",
        "!zip -r cnn_lstm_with_idle_savedmodel.zip /content/cnn_lstm_with_idle_savedmodel\n"
      ]
    }
  ]
}
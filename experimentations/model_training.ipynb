{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZiNoAUPs1ts",
        "outputId": "aecb6e1d-d0c5-49c2-e18f-e08fc4e00831"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted folders in /content:\n",
            "['Dataset_V2']\n"
          ]
        }
      ],
      "source": [
        "import zipfile, os\n",
        "\n",
        "ZIP_NAME = \"drive/MyDrive/Dataset_V2.zip\"  # must match the uploaded filename\n",
        "\n",
        "with zipfile.ZipFile(ZIP_NAME, 'r') as z:\n",
        "    z.extractall(\"/content\")\n",
        "\n",
        "print(\"Extracted folders in /content:\")\n",
        "print([p for p in os.listdir(\"/content\") if \"Dataset\" in p or \"dataset\" in p])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, glob\n",
        "\n",
        "DATASET_ROOT = \"/content/Dataset_V2\"  # adjust if unzip created a different name\n",
        "\n",
        "# Show top-level gesture folders\n",
        "print(\"Top-level folders (words):\")\n",
        "print([d for d in os.listdir(DATASET_ROOT) if os.path.isdir(os.path.join(DATASET_ROOT, d))][:20])\n",
        "\n",
        "# Show a few txt files\n",
        "some_txt = glob.glob(os.path.join(DATASET_ROOT, \"**\", \"*.txt\"), recursive=True)\n",
        "print(\"Found txt files:\", len(some_txt))\n",
        "print(\"Example files:\", some_txt[:5])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "529yY7LMwCfP",
        "outputId": "851c619b-fc45-4388-ec83-20d747fa4fd2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top-level folders (words):\n",
            "['saduda', 'narakai', 'pata', 'irida', 'awidinawa', 'hawasa', 'ada', 'udasana', 'hodai', 'boru']\n",
            "Found txt files: 1000\n",
            "Example files: ['/content/Dataset_V2/saduda/Day_4/saduda_4.txt', '/content/Dataset_V2/saduda/Day_4/saduda_7.txt', '/content/Dataset_V2/saduda/Day_4/saduda_2.txt', '/content/Dataset_V2/saduda/Day_4/saduda_8.txt', '/content/Dataset_V2/saduda/Day_4/saduda_1.txt']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def load_csv_robust(fp, expected_cols=10):\n",
        "    \"\"\"\n",
        "    Reads your file safely even if it contains:\n",
        "    - NULL bytes (\\x00)\n",
        "    - empty fields\n",
        "    - trailing commas\n",
        "    - corrupted rows\n",
        "    Returns: float32 array (N, expected_cols)\n",
        "    \"\"\"\n",
        "    # Read as bytes, kill nulls, decode safely\n",
        "    with open(fp, \"rb\") as f:\n",
        "        raw = f.read().replace(b\"\\x00\", b\"\")  # remove NULL bytes\n",
        "\n",
        "    text = raw.decode(\"utf-8\", errors=\"ignore\")\n",
        "\n",
        "    good_rows = []\n",
        "    bad = 0\n",
        "\n",
        "    for line in text.splitlines():\n",
        "        line = line.strip()\n",
        "        if not line:\n",
        "            continue\n",
        "\n",
        "        # Remove trailing commas: \"1,2,3,\" -> \"1,2,3\"\n",
        "        while line.endswith(\",\"):\n",
        "            line = line[:-1].strip()\n",
        "\n",
        "        parts = [p.strip() for p in line.split(\",\")]\n",
        "\n",
        "        # Must have expected columns\n",
        "        if len(parts) != expected_cols:\n",
        "            bad += 1\n",
        "            continue\n",
        "\n",
        "        # Must not contain empty fields\n",
        "        if any(p == \"\" for p in parts):\n",
        "            bad += 1\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            row = [float(p) for p in parts]\n",
        "            good_rows.append(row)\n",
        "        except:\n",
        "            bad += 1\n",
        "\n",
        "    if not good_rows:\n",
        "        raise ValueError(f\"No valid numeric rows found in {fp}. Bad rows={bad}\")\n",
        "\n",
        "    arr = np.array(good_rows, dtype=np.float32)\n",
        "    return arr, bad\n"
      ],
      "metadata": {
        "id": "XqLAI_j-xdCw"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "fp = some_txt[0]\n",
        "x = np.loadtxt(fp, delimiter=\",\", dtype=np.float32)\n",
        "print(\"Example file:\", fp)\n",
        "print(\"Shape:\", x.shape)   # expect (~800, 10)\n",
        "print(\"First row:\", x[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "UY16_4xTwwg-",
        "outputId": "559a9c9b-bfc5-43ac-d1df-54515dcc6b9c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "could not convert string '\\x006253857' to float32 at row 354, column 1.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;31mValueError\u001b[0m: could not convert string to float: ''",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-510034340.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msome_txt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Example file:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Shape:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# expect (~800, 10)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numpy/lib/_npyio_impl.py\u001b[0m in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows, quotechar, like)\u001b[0m\n\u001b[1;32m   1379\u001b[0m         \u001b[0mdelimiter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'latin1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1381\u001b[0;31m     arr = _read(fname, dtype=dtype, comment=comment, delimiter=delimiter,\n\u001b[0m\u001b[1;32m   1382\u001b[0m                 \u001b[0mconverters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconverters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskiplines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskiprows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musecols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1383\u001b[0m                 \u001b[0munpack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mndmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numpy/lib/_npyio_impl.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(fname, delimiter, comment, quote, imaginary_unit, usecols, skiplines, max_rows, converters, ndmin, unpack, dtype, encoding)\u001b[0m\n\u001b[1;32m   1019\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1020\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mread_dtype_via_object_chunks\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m             arr = _load_from_filelike(\n\u001b[0m\u001b[1;32m   1022\u001b[0m                 \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdelimiter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcomment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquote\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquote\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m                 \u001b[0mimaginary_unit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimaginary_unit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: could not convert string '\\x006253857' to float32 at row 354, column 1."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, glob\n",
        "\n",
        "DATASET_ROOT = \"/content/Dataset_V2\"\n",
        "\n",
        "days = set()\n",
        "for fp in glob.glob(os.path.join(DATASET_ROOT, \"**\", \"*.txt\"), recursive=True):\n",
        "    day_name = os.path.basename(os.path.dirname(fp))   # parent folder name\n",
        "    days.add(day_name)\n",
        "\n",
        "print(\"Days found:\", sorted(days))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_fgrVa-T6DA1",
        "outputId": "a17aa991-dc13-4a5b-b38e-89f31a703c2d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Days found: ['Day_1', 'Day_10', 'Day_2', 'Day_3', 'Day_4', 'Day_5', 'Day_6', 'Day_7', 'Day_8', 'Day_9']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def moving_average(x, w=25):\n",
        "    # w=25 at 100Hz ~ 0.25s smoothing\n",
        "    w = max(1, int(w))\n",
        "    kernel = np.ones(w, dtype=np.float32) / w\n",
        "    return np.convolve(x, kernel, mode=\"same\")\n",
        "\n",
        "def crop_active_region_emg(X, target_len=512, smooth_w=25, thresh_ratio=0.25):\n",
        "    \"\"\"\n",
        "    X: (Traw, 9), EMG channels are X[:,0:3]\n",
        "    Returns: (target_len, 9) by cropping around the active EMG region.\n",
        "\n",
        "    thresh_ratio: relative threshold vs max energy (0.2~0.35 works well)\n",
        "    \"\"\"\n",
        "    Traw = X.shape[0]\n",
        "    if Traw == 0:\n",
        "        return np.zeros((target_len, X.shape[1]), dtype=np.float32)\n",
        "\n",
        "    # EMG energy signal (rectified + sum across 3 channels)\n",
        "    emg = X[:, :3]\n",
        "    energy = np.sum(np.abs(emg), axis=1)\n",
        "\n",
        "    # Smooth energy so it’s stable\n",
        "    energy_s = moving_average(energy, w=smooth_w)\n",
        "\n",
        "    # Find active frames using relative threshold\n",
        "    mx = float(np.max(energy_s))\n",
        "    if mx <= 1e-6:\n",
        "        # no activity detected -> fallback to center crop/pad\n",
        "        return fix_length_center(X, target_len)\n",
        "\n",
        "    thresh = thresh_ratio * mx\n",
        "    active = np.where(energy_s >= thresh)[0]\n",
        "\n",
        "    if len(active) < 5:\n",
        "        # not enough detected activity -> fallback\n",
        "        return fix_length_center(X, target_len)\n",
        "\n",
        "    start = int(active[0])\n",
        "    end   = int(active[-1])\n",
        "\n",
        "    # Center crop window around the active segment\n",
        "    center = (start + end) // 2\n",
        "    half = target_len // 2\n",
        "    win_start = max(0, center - half)\n",
        "    win_end = win_start + target_len\n",
        "\n",
        "    # If window goes beyond the end, shift it back\n",
        "    if win_end > Traw:\n",
        "        win_end = Traw\n",
        "        win_start = max(0, win_end - target_len)\n",
        "\n",
        "    cropped = X[win_start:win_end]\n",
        "\n",
        "    # Pad if still shorter\n",
        "    if cropped.shape[0] < target_len:\n",
        "        pad = np.zeros((target_len - cropped.shape[0], X.shape[1]), dtype=cropped.dtype)\n",
        "        cropped = np.vstack([cropped, pad])\n",
        "\n",
        "    return cropped\n"
      ],
      "metadata": {
        "id": "pqUbd_OF2sq4"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, glob, json\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "# =======================\n",
        "# CONFIG (Option 1)\n",
        "# =======================\n",
        "DATASET_ROOT = \"/content/Dataset_V2\"  # <-- set correctly\n",
        "T = 512   # ~8 sec @100Hz (800). 768 is convenient for pooling.\n",
        "SEED = 42\n",
        "EPOCHS = 60\n",
        "BATCH = 32\n",
        "LR = 1e-3\n",
        "\n",
        "tf.random.set_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "\n",
        "# =======================\n",
        "# DATA LOADING\n",
        "# =======================\n",
        "def build_label_map(root):\n",
        "    labels = sorted([d for d in os.listdir(root) if os.path.isdir(os.path.join(root, d))])\n",
        "    if not labels:\n",
        "        raise RuntimeError(f\"No class folders found in: {root}\")\n",
        "    return {lbl: i for i, lbl in enumerate(labels)}\n",
        "\n",
        "def load_one_sample_txt(path):\n",
        "    # CSV: t_ms, emg1, emg2, emg3, ax, ay, az, gx, gy, gz\n",
        "    data = np.loadtxt(path, delimiter=\",\", dtype=np.float32)\n",
        "    if data.ndim == 1:\n",
        "        data = data[None, :]\n",
        "    X = data[:, 1:]  # drop timestamp -> (Traw, 9)\n",
        "    if X.shape[1] != 9:\n",
        "        raise ValueError(f\"{path}: expected 9 features after timestamp, got {X.shape[1]}\")\n",
        "    return X\n",
        "\n",
        "def fix_length_center(X, T):\n",
        "    if len(X) >= T:\n",
        "        start = (len(X) - T) // 2\n",
        "        return X[start:start + T]\n",
        "    pad = np.zeros((T - len(X), X.shape[1]), dtype=X.dtype)\n",
        "    return np.vstack([X, pad])\n",
        "\n",
        "def emg_dc_remove(X):\n",
        "    X = X.copy()\n",
        "    X[:, :3] -= X[:, :3].mean(axis=0, keepdims=True)\n",
        "    return X\n",
        "\n",
        "def load_dataset(root, T):\n",
        "    label2id = build_label_map(root)\n",
        "    X_list, y_list = [], []\n",
        "    skipped = 0\n",
        "\n",
        "    for label, lab_id in label2id.items():\n",
        "        class_dir = os.path.join(root, label)\n",
        "        files = sorted(glob.glob(os.path.join(class_dir, \"**\", \"*.txt\"), recursive=True))\n",
        "        for fp in files:\n",
        "            try:\n",
        "                X = load_one_sample_txt(fp)\n",
        "                X = emg_dc_remove(X)\n",
        "                X = crop_active_region_emg(X, target_len=T, smooth_w=25, thresh_ratio=0.25)\n",
        "                X_list.append(X)\n",
        "                y_list.append(lab_id)\n",
        "            except Exception as e:\n",
        "                skipped += 1\n",
        "                # print(\"[SKIP]\", fp, \"->\", e)\n",
        "\n",
        "    if not X_list:\n",
        "        raise RuntimeError(\"No samples loaded. Check DATASET_ROOT and file format.\")\n",
        "\n",
        "    X_all = np.stack(X_list, axis=0)           # (N, T, 9)\n",
        "    y_all = np.array(y_list, dtype=np.int64)\n",
        "\n",
        "    print(\"Loaded:\", X_all.shape, \"classes:\", len(label2id), \"skipped:\", skipped)\n",
        "    counts = {k: int((y_all == v).sum()) for k, v in label2id.items()}\n",
        "    print(\"Per-class counts:\", counts)\n",
        "\n",
        "    return X_all, y_all, label2id\n",
        "\n",
        "def normalize_train_only(X_train, X_val, X_test):\n",
        "    N, T, F = X_train.shape\n",
        "    scaler = StandardScaler()\n",
        "    scaler.fit(X_train.reshape(-1, F))\n",
        "    X_train = scaler.transform(X_train.reshape(-1, F)).reshape(N, T, F)\n",
        "    X_val   = scaler.transform(X_val.reshape(-1, F)).reshape(X_val.shape[0], T, F)\n",
        "    X_test  = scaler.transform(X_test.reshape(-1, F)).reshape(X_test.shape[0], T, F)\n",
        "    return X_train, X_val, X_test, scaler\n",
        "\n",
        "# =======================\n",
        "# MODEL: CNN + LSTM\n",
        "# =======================\n",
        "def build_cnn_lstm(T, F, num_classes):\n",
        "    inp = layers.Input(shape=(T, F))\n",
        "\n",
        "    x = layers.Conv1D(64, 5, padding=\"same\")(inp)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "    x = layers.MaxPool1D(2)(x)\n",
        "\n",
        "    x = layers.Conv1D(128, 3, padding=\"same\")(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "    x = layers.MaxPool1D(2)(x)\n",
        "\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "    x = layers.LSTM(128)(x)\n",
        "    x = layers.Dropout(0.4)(x)\n",
        "\n",
        "    x = layers.Dense(128, activation=\"relu\")(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "\n",
        "    out = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
        "\n",
        "    model = models.Model(inp, out)\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(LR),\n",
        "        loss=\"sparse_categorical_crossentropy\",\n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "    return model\n",
        "\n",
        "def evaluate(model, X_test, y_test, id2label):\n",
        "    pred = model.predict(X_test, verbose=0).argmax(axis=1)\n",
        "    print(\"\\nClassification report:\")\n",
        "    print(classification_report(\n",
        "        y_test, pred,\n",
        "        target_names=[id2label[i] for i in range(len(id2label))],\n",
        "        digits=4\n",
        "    ))\n",
        "    cm = confusion_matrix(y_test, pred)\n",
        "    print(\"\\nConfusion matrix (rows=true, cols=pred):\")\n",
        "    print(cm)\n",
        "\n",
        "# =======================\n",
        "# TRAIN\n",
        "# =======================\n",
        "X, y, label2id = load_dataset(DATASET_ROOT, T)\n",
        "id2label = {v: k for k, v in label2id.items()}\n",
        "\n",
        "X_train, X_tmp, y_train, y_tmp = train_test_split(\n",
        "    X, y, test_size=0.30, random_state=SEED, stratify=y\n",
        ")\n",
        "X_val, X_test, y_val, y_test = train_test_split(\n",
        "    X_tmp, y_tmp, test_size=0.50, random_state=SEED, stratify=y_tmp\n",
        ")\n",
        "\n",
        "X_train, X_val, X_test, scaler = normalize_train_only(X_train, X_val, X_test)\n",
        "\n",
        "model = build_cnn_lstm(T, X_train.shape[-1], len(label2id))\n",
        "model.summary()\n",
        "\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.ModelCheckpoint(\"/content/cnn_lstm_best.keras\", monitor=\"val_accuracy\", save_best_only=True),\n",
        "    tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\", patience=10, restore_best_weights=True),\n",
        "    tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=5, min_lr=1e-6),\n",
        "]\n",
        "\n",
        "model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=EPOCHS,\n",
        "    batch_size=BATCH,\n",
        "    shuffle=True,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"\\n✅ Test accuracy (random split): {acc:.4f}\")\n",
        "\n",
        "evaluate(model, X_test, y_test, id2label)\n",
        "\n",
        "with open(\"/content/label_map.json\", \"w\") as f:\n",
        "    json.dump(label2id, f, indent=2)\n",
        "\n",
        "print(\"\\nSaved to /content: cnn_lstm_best.keras, label_map.json\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MLclPJvzxvS3",
        "outputId": "b7634dd5-8ada-474a-9774-0a461392d7d5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded: (632, 512, 9) classes: 10 skipped: 368\n",
            "Per-class counts: {'ada': 53, 'awidinawa': 77, 'boru': 61, 'hawasa': 58, 'hodai': 68, 'irida': 52, 'narakai': 53, 'pata': 64, 'saduda': 75, 'udasana': 71}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m9\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │         \u001b[38;5;34m2,944\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ re_lu (\u001b[38;5;33mReLU\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m24,704\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ re_lu_1 (\u001b[38;5;33mReLU\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m131,584\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m16,512\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,290\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,944</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ re_lu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ re_lu_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m177,802\u001b[0m (694.54 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">177,802</span> (694.54 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m177,418\u001b[0m (693.04 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">177,418</span> (693.04 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m384\u001b[0m (1.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> (1.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/60\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 310ms/step - accuracy: 0.1270 - loss: 2.3334 - val_accuracy: 0.2105 - val_loss: 2.2246 - learning_rate: 0.0010\n",
            "Epoch 2/60\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 346ms/step - accuracy: 0.2801 - loss: 2.0808 - val_accuracy: 0.2105 - val_loss: 2.0850 - learning_rate: 0.0010\n",
            "Epoch 3/60\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 392ms/step - accuracy: 0.3647 - loss: 1.8786 - val_accuracy: 0.3158 - val_loss: 1.9605 - learning_rate: 0.0010\n",
            "Epoch 4/60\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 697ms/step - accuracy: 0.3772 - loss: 1.7390 - val_accuracy: 0.4316 - val_loss: 1.7744 - learning_rate: 0.0010\n",
            "Epoch 5/60\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 259ms/step - accuracy: 0.3619 - loss: 1.6549 - val_accuracy: 0.4737 - val_loss: 1.6127 - learning_rate: 0.0010\n",
            "Epoch 6/60\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 265ms/step - accuracy: 0.4270 - loss: 1.4402 - val_accuracy: 0.5474 - val_loss: 1.4401 - learning_rate: 0.0010\n",
            "Epoch 7/60\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 311ms/step - accuracy: 0.5455 - loss: 1.2512 - val_accuracy: 0.4842 - val_loss: 1.3873 - learning_rate: 0.0010\n",
            "Epoch 8/60\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 248ms/step - accuracy: 0.6304 - loss: 1.0882 - val_accuracy: 0.5053 - val_loss: 1.2676 - learning_rate: 0.0010\n",
            "Epoch 9/60\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 360ms/step - accuracy: 0.6109 - loss: 1.0390 - val_accuracy: 0.5158 - val_loss: 1.2856 - learning_rate: 0.0010\n",
            "Epoch 10/60\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 264ms/step - accuracy: 0.6498 - loss: 0.9518 - val_accuracy: 0.5789 - val_loss: 1.1172 - learning_rate: 0.0010\n",
            "Epoch 11/60\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 257ms/step - accuracy: 0.6900 - loss: 0.8614 - val_accuracy: 0.6211 - val_loss: 1.0366 - learning_rate: 0.0010\n",
            "Epoch 12/60\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 291ms/step - accuracy: 0.7496 - loss: 0.7339 - val_accuracy: 0.6211 - val_loss: 1.2513 - learning_rate: 0.0010\n",
            "Epoch 13/60\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 381ms/step - accuracy: 0.8234 - loss: 0.6028 - val_accuracy: 0.6947 - val_loss: 0.8500 - learning_rate: 0.0010\n",
            "Epoch 14/60\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 319ms/step - accuracy: 0.8146 - loss: 0.5391 - val_accuracy: 0.6526 - val_loss: 1.0139 - learning_rate: 0.0010\n",
            "Epoch 15/60\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 308ms/step - accuracy: 0.8336 - loss: 0.5113 - val_accuracy: 0.7684 - val_loss: 0.6470 - learning_rate: 0.0010\n",
            "Epoch 16/60\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 258ms/step - accuracy: 0.8506 - loss: 0.4217 - val_accuracy: 0.7895 - val_loss: 0.6079 - learning_rate: 0.0010\n",
            "Epoch 17/60\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 334ms/step - accuracy: 0.9234 - loss: 0.2829 - val_accuracy: 0.8105 - val_loss: 0.5022 - learning_rate: 0.0010\n",
            "Epoch 18/60\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 294ms/step - accuracy: 0.9356 - loss: 0.2283 - val_accuracy: 0.7368 - val_loss: 0.7645 - learning_rate: 0.0010\n",
            "Epoch 19/60\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 264ms/step - accuracy: 0.8598 - loss: 0.3266 - val_accuracy: 0.8000 - val_loss: 0.5702 - learning_rate: 0.0010\n",
            "Epoch 20/60\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 258ms/step - accuracy: 0.8845 - loss: 0.3503 - val_accuracy: 0.8000 - val_loss: 0.6274 - learning_rate: 0.0010\n",
            "Epoch 21/60\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 375ms/step - accuracy: 0.8626 - loss: 0.3524 - val_accuracy: 0.8316 - val_loss: 0.5344 - learning_rate: 0.0010\n",
            "Epoch 22/60\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 268ms/step - accuracy: 0.8836 - loss: 0.2886 - val_accuracy: 0.7789 - val_loss: 0.6026 - learning_rate: 0.0010\n",
            "Epoch 23/60\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 367ms/step - accuracy: 0.9069 - loss: 0.2751 - val_accuracy: 0.8211 - val_loss: 0.5073 - learning_rate: 5.0000e-04\n",
            "Epoch 24/60\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 259ms/step - accuracy: 0.9275 - loss: 0.2332 - val_accuracy: 0.8000 - val_loss: 0.5413 - learning_rate: 5.0000e-04\n",
            "Epoch 25/60\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 392ms/step - accuracy: 0.9553 - loss: 0.1489 - val_accuracy: 0.8526 - val_loss: 0.4099 - learning_rate: 5.0000e-04\n",
            "Epoch 26/60\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 270ms/step - accuracy: 0.9755 - loss: 0.1032 - val_accuracy: 0.8632 - val_loss: 0.4592 - learning_rate: 5.0000e-04\n",
            "Epoch 27/60\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 302ms/step - accuracy: 0.9830 - loss: 0.0794 - val_accuracy: 0.8737 - val_loss: 0.3966 - learning_rate: 5.0000e-04\n",
            "Epoch 28/60\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 263ms/step - accuracy: 0.9790 - loss: 0.0592 - val_accuracy: 0.8737 - val_loss: 0.3733 - learning_rate: 5.0000e-04\n",
            "Epoch 29/60\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 310ms/step - accuracy: 0.9666 - loss: 0.0976 - val_accuracy: 0.8526 - val_loss: 0.5667 - learning_rate: 5.0000e-04\n",
            "Epoch 30/60\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 293ms/step - accuracy: 0.9558 - loss: 0.1208 - val_accuracy: 0.8947 - val_loss: 0.3353 - learning_rate: 5.0000e-04\n",
            "Epoch 31/60\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 255ms/step - accuracy: 0.9727 - loss: 0.0879 - val_accuracy: 0.8632 - val_loss: 0.4498 - learning_rate: 5.0000e-04\n",
            "Epoch 32/60\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 250ms/step - accuracy: 0.9778 - loss: 0.0667 - val_accuracy: 0.8632 - val_loss: 0.4378 - learning_rate: 5.0000e-04\n",
            "Epoch 33/60\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 369ms/step - accuracy: 0.9820 - loss: 0.0605 - val_accuracy: 0.8842 - val_loss: 0.3940 - learning_rate: 5.0000e-04\n",
            "Epoch 34/60\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 253ms/step - accuracy: 0.9959 - loss: 0.0375 - val_accuracy: 0.8947 - val_loss: 0.3996 - learning_rate: 5.0000e-04\n",
            "Epoch 35/60\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 262ms/step - accuracy: 0.9949 - loss: 0.0331 - val_accuracy: 0.8947 - val_loss: 0.3528 - learning_rate: 5.0000e-04\n",
            "Epoch 36/60\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 413ms/step - accuracy: 0.9952 - loss: 0.0248 - val_accuracy: 0.8947 - val_loss: 0.3358 - learning_rate: 2.5000e-04\n",
            "Epoch 37/60\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.9987 - loss: 0.0242 - val_accuracy: 0.9158 - val_loss: 0.3488 - learning_rate: 2.5000e-04\n",
            "Epoch 38/60\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 259ms/step - accuracy: 0.9990 - loss: 0.0203 - val_accuracy: 0.9158 - val_loss: 0.3615 - learning_rate: 2.5000e-04\n",
            "Epoch 39/60\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 337ms/step - accuracy: 0.9959 - loss: 0.0184 - val_accuracy: 0.9053 - val_loss: 0.3772 - learning_rate: 2.5000e-04\n",
            "Epoch 40/60\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 258ms/step - accuracy: 0.9985 - loss: 0.0184 - val_accuracy: 0.9053 - val_loss: 0.4015 - learning_rate: 2.5000e-04\n",
            "Epoch 41/60\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 250ms/step - accuracy: 1.0000 - loss: 0.0278 - val_accuracy: 0.9053 - val_loss: 0.4046 - learning_rate: 1.2500e-04\n",
            "Epoch 42/60\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 325ms/step - accuracy: 1.0000 - loss: 0.0166 - val_accuracy: 0.8947 - val_loss: 0.4095 - learning_rate: 1.2500e-04\n",
            "Epoch 43/60\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 252ms/step - accuracy: 0.9990 - loss: 0.0130 - val_accuracy: 0.9053 - val_loss: 0.4152 - learning_rate: 1.2500e-04\n",
            "Epoch 44/60\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 312ms/step - accuracy: 1.0000 - loss: 0.0135 - val_accuracy: 0.9053 - val_loss: 0.4161 - learning_rate: 1.2500e-04\n",
            "Epoch 45/60\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 311ms/step - accuracy: 1.0000 - loss: 0.0169 - val_accuracy: 0.8947 - val_loss: 0.4183 - learning_rate: 1.2500e-04\n",
            "Epoch 46/60\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 256ms/step - accuracy: 0.9995 - loss: 0.0164 - val_accuracy: 0.8842 - val_loss: 0.4188 - learning_rate: 6.2500e-05\n",
            "Epoch 47/60\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 275ms/step - accuracy: 0.9964 - loss: 0.0184 - val_accuracy: 0.8842 - val_loss: 0.4220 - learning_rate: 6.2500e-05\n",
            "\n",
            "✅ Test accuracy (random split): 0.9368\n",
            "\n",
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ada     0.8889    1.0000    0.9412         8\n",
            "   awidinawa     1.0000    0.9091    0.9524        11\n",
            "        boru     0.8000    0.8889    0.8421         9\n",
            "      hawasa     0.8889    1.0000    0.9412         8\n",
            "       hodai     0.9091    0.9091    0.9091        11\n",
            "       irida     1.0000    1.0000    1.0000         8\n",
            "     narakai     1.0000    1.0000    1.0000         8\n",
            "        pata     0.9091    1.0000    0.9524        10\n",
            "      saduda     1.0000    0.9167    0.9565        12\n",
            "     udasana     1.0000    0.8000    0.8889        10\n",
            "\n",
            "    accuracy                         0.9368        95\n",
            "   macro avg     0.9396    0.9424    0.9384        95\n",
            "weighted avg     0.9422    0.9368    0.9369        95\n",
            "\n",
            "\n",
            "Confusion matrix (rows=true, cols=pred):\n",
            "[[ 8  0  0  0  0  0  0  0  0  0]\n",
            " [ 1 10  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  8  0  1  0  0  0  0  0]\n",
            " [ 0  0  0  8  0  0  0  0  0  0]\n",
            " [ 0  0  1  0 10  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  8  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  8  0  0  0]\n",
            " [ 0  0  0  0  0  0  0 10  0  0]\n",
            " [ 0  0  1  0  0  0  0  0 11  0]\n",
            " [ 0  0  0  1  0  0  0  1  0  8]]\n",
            "\n",
            "Saved to /content: cnn_lstm_best.keras, label_map.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, glob, json\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "# =======================\n",
        "# CONFIG\n",
        "# =======================\n",
        "DATASET_ROOT = \"/content/Dataset_V2\"\n",
        "TRAIN_DAY = \"Day_1\"\n",
        "TEST_DAY  = \"Day_2\"\n",
        "\n",
        "T = 512           # Option 2 window\n",
        "SEED = 42\n",
        "EPOCHS = 60\n",
        "BATCH = 32\n",
        "LR = 1e-3\n",
        "\n",
        "tf.random.set_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "\n",
        "# =======================\n",
        "# Robust reader (if you used it earlier)\n",
        "# If your files are now clean, you can skip this and use np.loadtxt\n",
        "# =======================\n",
        "def load_csv_robust(fp, expected_cols=10):\n",
        "    with open(fp, \"rb\") as f:\n",
        "        raw = f.read().replace(b\"\\x00\", b\"\")\n",
        "    text = raw.decode(\"utf-8\", errors=\"ignore\")\n",
        "\n",
        "    good_rows = []\n",
        "    for line in text.splitlines():\n",
        "        line = line.strip()\n",
        "        if not line:\n",
        "            continue\n",
        "        while line.endswith(\",\"):\n",
        "            line = line[:-1].strip()\n",
        "        parts = [p.strip() for p in line.split(\",\")]\n",
        "        if len(parts) != expected_cols:\n",
        "            continue\n",
        "        if any(p == \"\" for p in parts):\n",
        "            continue\n",
        "        try:\n",
        "            good_rows.append([float(p) for p in parts])\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "    if not good_rows:\n",
        "        raise ValueError(f\"No valid numeric rows in {fp}\")\n",
        "    return np.array(good_rows, dtype=np.float32)\n",
        "\n",
        "# =======================\n",
        "# Cropping (Option 2)\n",
        "# =======================\n",
        "def moving_average(x, w=25):\n",
        "    w = max(1, int(w))\n",
        "    kernel = np.ones(w, dtype=np.float32) / w\n",
        "    return np.convolve(x, kernel, mode=\"same\")\n",
        "\n",
        "def fix_length_center(X, target_len):\n",
        "    if len(X) >= target_len:\n",
        "        start = (len(X) - target_len) // 2\n",
        "        return X[start:start + target_len]\n",
        "    pad = np.zeros((target_len - len(X), X.shape[1]), dtype=X.dtype)\n",
        "    return np.vstack([X, pad])\n",
        "\n",
        "def emg_dc_remove(X):\n",
        "    X = X.copy()\n",
        "    X[:, :3] -= X[:, :3].mean(axis=0, keepdims=True)\n",
        "    return X\n",
        "\n",
        "def crop_active_region_emg(X, target_len=512, smooth_w=25, thresh_ratio=0.25):\n",
        "    Traw = X.shape[0]\n",
        "    if Traw == 0:\n",
        "        return np.zeros((target_len, X.shape[1]), dtype=np.float32)\n",
        "\n",
        "    energy = np.sum(np.abs(X[:, :3]), axis=1)\n",
        "    energy_s = moving_average(energy, w=smooth_w)\n",
        "\n",
        "    mx = float(np.max(energy_s))\n",
        "    if mx <= 1e-6:\n",
        "        return fix_length_center(X, target_len)\n",
        "\n",
        "    thresh = thresh_ratio * mx\n",
        "    active = np.where(energy_s >= thresh)[0]\n",
        "    if len(active) < 5:\n",
        "        return fix_length_center(X, target_len)\n",
        "\n",
        "    start = int(active[0])\n",
        "    end   = int(active[-1])\n",
        "    center = (start + end) // 2\n",
        "\n",
        "    half = target_len // 2\n",
        "    win_start = max(0, center - half)\n",
        "    win_end = win_start + target_len\n",
        "    if win_end > Traw:\n",
        "        win_end = Traw\n",
        "        win_start = max(0, win_end - target_len)\n",
        "\n",
        "    cropped = X[win_start:win_end]\n",
        "    if cropped.shape[0] < target_len:\n",
        "        pad = np.zeros((target_len - cropped.shape[0], X.shape[1]), dtype=cropped.dtype)\n",
        "        cropped = np.vstack([cropped, pad])\n",
        "    return cropped\n",
        "\n",
        "# =======================\n",
        "# Dataset loading with DAY metadata\n",
        "# =======================\n",
        "def build_label_map(root):\n",
        "    labels = sorted([d for d in os.listdir(root) if os.path.isdir(os.path.join(root, d))])\n",
        "    return {lbl: i for i, lbl in enumerate(labels)}\n",
        "\n",
        "def load_one_sample(path):\n",
        "    arr = load_csv_robust(path, expected_cols=10)    # (Traw, 10)\n",
        "    X = arr[:, 1:]                                   # drop timestamp -> (Traw, 9)\n",
        "    X = emg_dc_remove(X)\n",
        "    X = crop_active_region_emg(X, target_len=T, smooth_w=25, thresh_ratio=0.25)\n",
        "    return X\n",
        "\n",
        "def load_dataset_with_days(root):\n",
        "    label2id = build_label_map(root)\n",
        "    X_list, y_list, day_list = [], [], []\n",
        "\n",
        "    for label, lab_id in label2id.items():\n",
        "        class_dir = os.path.join(root, label)\n",
        "        files = sorted(glob.glob(os.path.join(class_dir, \"**\", \"*.txt\"), recursive=True))\n",
        "\n",
        "        for fp in files:\n",
        "            day_name = os.path.basename(os.path.dirname(fp))  # parent folder: day_1\n",
        "            try:\n",
        "                X = load_one_sample(fp)\n",
        "                X_list.append(X)\n",
        "                y_list.append(lab_id)\n",
        "                day_list.append(day_name)\n",
        "            except Exception as e:\n",
        "                # print(\"[SKIP]\", fp, \"->\", e)\n",
        "                pass\n",
        "\n",
        "    X_all = np.stack(X_list, axis=0)  # (N, T, 9)\n",
        "    y_all = np.array(y_list, dtype=np.int64)\n",
        "    days  = np.array(day_list)\n",
        "\n",
        "    print(\"Loaded:\", X_all.shape, \"classes:\", len(label2id))\n",
        "    print(\"Days present:\", sorted(set(days.tolist())))\n",
        "    return X_all, y_all, days, label2id\n",
        "\n",
        "def normalize_train_only(X_train, X_val, X_test):\n",
        "    N, TT, F = X_train.shape\n",
        "    scaler = StandardScaler()\n",
        "    scaler.fit(X_train.reshape(-1, F))\n",
        "\n",
        "    X_train = scaler.transform(X_train.reshape(-1, F)).reshape(N, TT, F)\n",
        "    X_val   = scaler.transform(X_val.reshape(-1, F)).reshape(X_val.shape[0], TT, F)\n",
        "    X_test  = scaler.transform(X_test.reshape(-1, F)).reshape(X_test.shape[0], TT, F)\n",
        "\n",
        "    return X_train, X_val, X_test, scaler\n",
        "\n",
        "\n",
        "# =======================\n",
        "# Model\n",
        "# =======================\n",
        "def build_cnn_lstm(T, F, num_classes):\n",
        "    inp = layers.Input(shape=(T, F))\n",
        "\n",
        "    x = layers.Conv1D(64, 5, padding=\"same\")(inp)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "    x = layers.MaxPool1D(2)(x)\n",
        "\n",
        "    x = layers.Conv1D(128, 3, padding=\"same\")(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "    x = layers.MaxPool1D(2)(x)\n",
        "\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "    x = layers.LSTM(128)(x)\n",
        "    x = layers.Dropout(0.4)(x)\n",
        "\n",
        "    x = layers.Dense(128, activation=\"relu\")(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "\n",
        "    out = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
        "\n",
        "    model = models.Model(inp, out)\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(LR),\n",
        "        loss=\"sparse_categorical_crossentropy\",\n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "    return model\n",
        "\n",
        "def evaluate(model, X_test, y_test, id2label):\n",
        "    pred = model.predict(X_test, verbose=0).argmax(axis=1)\n",
        "    print(\"\\nClassification report:\")\n",
        "    print(classification_report(\n",
        "        y_test, pred,\n",
        "        target_names=[id2label[i] for i in range(len(id2label))],\n",
        "        digits=4\n",
        "    ))\n",
        "    cm = confusion_matrix(y_test, pred)\n",
        "    print(\"\\nConfusion matrix (rows=true, cols=pred):\")\n",
        "    print(cm)\n",
        "\n",
        "# =======================\n",
        "# RUN: Day-wise split\n",
        "# =======================\n",
        "X, y, days, label2id = load_dataset_with_days(DATASET_ROOT)\n",
        "id2label = {v:k for k,v in label2id.items()}\n",
        "\n",
        "TRAIN_DAYS = {f\"Day_{i}\" for i in range(1, 9)}   # Day_1..Day_8\n",
        "VAL_DAYS   = {\"Day_9\"}\n",
        "TEST_DAYS  = {\"Day_10\"}\n",
        "\n",
        "train_mask = np.isin(days, list(TRAIN_DAYS))\n",
        "val_mask   = np.isin(days, list(VAL_DAYS))\n",
        "test_mask  = np.isin(days, list(TEST_DAYS))\n",
        "\n",
        "print(\"Train samples:\", train_mask.sum())\n",
        "print(\"Val samples:\", val_mask.sum())\n",
        "print(\"Test samples:\", test_mask.sum())\n",
        "\n",
        "X_train, y_train = X[train_mask], y[train_mask]\n",
        "X_val,   y_val   = X[val_mask],   y[val_mask]\n",
        "X_test,  y_test  = X[test_mask],  y[test_mask]\n",
        "\n",
        "# Normalize\n",
        "X_train, X_val, X_test, scaler = normalize_train_only(X_train, X_val, X_test)\n",
        "\n",
        "\n",
        "model = build_cnn_lstm(T, X_train.shape[-1], len(label2id))\n",
        "model.summary()\n",
        "\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\", patience=10, restore_best_weights=True),\n",
        "    tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=5, min_lr=1e-6),\n",
        "]\n",
        "\n",
        "model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=EPOCHS,\n",
        "    batch_size=BATCH,\n",
        "    shuffle=True,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"✅ Test accuracy (Day_1–8 → Day_10):\", acc)\n",
        "\n",
        "evaluate(model, X_test, y_test, id2label)\n",
        "\n",
        "# MODEL_PATH = \"/content/cnn_lstm_baseline.keras\"\n",
        "# model.save(MODEL_PATH)\n",
        "# print(\"Saved model to:\", MODEL_PATH)\n",
        "\n",
        "# LABEL_MAP_PATH = \"/content/label_map.json\"\n",
        "# with open(LABEL_MAP_PATH, \"w\") as f:\n",
        "#     json.dump(label2id, f, indent=2)\n",
        "\n",
        "# print(\"Saved label map to:\", LABEL_MAP_PATH)\n",
        "\n",
        "# SCALER_PATH = \"/content/scaler_params.json\"\n",
        "# scaler_params = {\n",
        "#     \"mean\": scaler.mean_.tolist(),\n",
        "#     \"scale\": scaler.scale_.tolist()\n",
        "# }\n",
        "\n",
        "# with open(SCALER_PATH, \"w\") as f:\n",
        "#     json.dump(scaler_params, f, indent=2)\n",
        "\n",
        "# print(\"Saved scaler params to:\", SCALER_PATH)\n",
        "\n",
        "\n",
        "\n",
        "# Force-save model in TF-compatible HDF5 format\n",
        "model.save(\"cnn_lstm_baseline.h5\", save_format=\"h5\")\n",
        "print(\"Saved cnn_lstm_baseline.h5\")\n",
        "\n",
        "# Also resave label map + scaler (just to be safe)\n",
        "import json\n",
        "\n",
        "with open(\"label_map.json\", \"w\") as f:\n",
        "    json.dump(label2id, f, indent=2)\n",
        "\n",
        "scaler_params = {\n",
        "    \"mean\": scaler.mean_.tolist(),\n",
        "    \"scale\": scaler.scale_.tolist()\n",
        "}\n",
        "with open(\"scaler_params.json\", \"w\") as f:\n",
        "    json.dump(scaler_params, f, indent=2)\n",
        "\n",
        "# Save as TensorFlow SavedModel (folder)\n",
        "model.export(\"/content/cnn_lstm_savedmodel\")\n",
        "print(\"Saved SavedModel to /content/cnn_lstm_savedmodel\")\n",
        "\n",
        "!zip -r cnn_lstm_savedmodel.zip /content/cnn_lstm_savedmodel\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6yccIXAw6YyZ",
        "outputId": "62c318c3-41b5-48eb-e304-5c303ad34b3b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded: (1000, 512, 9) classes: 10\n",
            "Days present: ['Day_1', 'Day_10', 'Day_2', 'Day_3', 'Day_4', 'Day_5', 'Day_6', 'Day_7', 'Day_8', 'Day_9']\n",
            "Train samples: 801\n",
            "Val samples: 100\n",
            "Test samples: 99\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_3 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m9\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_6 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │         \u001b[38;5;34m2,944\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_6           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ re_lu_6 (\u001b[38;5;33mReLU\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_6 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_7 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m24,704\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_7           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ re_lu_7 (\u001b[38;5;33mReLU\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_7 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m131,584\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_10 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m16,512\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_11 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,290\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,944</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_6           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ re_lu_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_7           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ re_lu_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m177,802\u001b[0m (694.54 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">177,802</span> (694.54 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m177,418\u001b[0m (693.04 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">177,418</span> (693.04 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m384\u001b[0m (1.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> (1.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/60\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 276ms/step - accuracy: 0.1441 - loss: 2.2968 - val_accuracy: 0.1800 - val_loss: 2.1508 - learning_rate: 0.0010\n",
            "Epoch 2/60\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 236ms/step - accuracy: 0.2720 - loss: 1.9828 - val_accuracy: 0.1800 - val_loss: 2.0470 - learning_rate: 0.0010\n",
            "Epoch 3/60\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 238ms/step - accuracy: 0.3682 - loss: 1.8090 - val_accuracy: 0.3300 - val_loss: 1.6851 - learning_rate: 0.0010\n",
            "Epoch 4/60\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 305ms/step - accuracy: 0.3925 - loss: 1.6041 - val_accuracy: 0.4900 - val_loss: 1.4124 - learning_rate: 0.0010\n",
            "Epoch 5/60\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 236ms/step - accuracy: 0.4570 - loss: 1.3971 - val_accuracy: 0.4800 - val_loss: 1.2977 - learning_rate: 0.0010\n",
            "Epoch 6/60\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 300ms/step - accuracy: 0.5894 - loss: 1.1464 - val_accuracy: 0.3900 - val_loss: 1.6628 - learning_rate: 0.0010\n",
            "Epoch 7/60\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 233ms/step - accuracy: 0.6226 - loss: 1.0394 - val_accuracy: 0.6000 - val_loss: 0.9952 - learning_rate: 0.0010\n",
            "Epoch 8/60\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 301ms/step - accuracy: 0.6624 - loss: 0.8969 - val_accuracy: 0.6000 - val_loss: 1.0714 - learning_rate: 0.0010\n",
            "Epoch 9/60\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 238ms/step - accuracy: 0.7009 - loss: 0.8469 - val_accuracy: 0.6600 - val_loss: 0.8838 - learning_rate: 0.0010\n",
            "Epoch 10/60\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 241ms/step - accuracy: 0.7888 - loss: 0.6093 - val_accuracy: 0.7500 - val_loss: 0.9065 - learning_rate: 0.0010\n",
            "Epoch 11/60\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 326ms/step - accuracy: 0.8442 - loss: 0.4340 - val_accuracy: 0.7100 - val_loss: 0.8610 - learning_rate: 0.0010\n",
            "Epoch 12/60\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 237ms/step - accuracy: 0.8582 - loss: 0.4167 - val_accuracy: 0.7400 - val_loss: 0.7345 - learning_rate: 0.0010\n",
            "Epoch 13/60\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 311ms/step - accuracy: 0.9118 - loss: 0.2455 - val_accuracy: 0.7400 - val_loss: 0.7581 - learning_rate: 0.0010\n",
            "Epoch 14/60\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 269ms/step - accuracy: 0.9065 - loss: 0.2788 - val_accuracy: 0.8900 - val_loss: 0.3873 - learning_rate: 0.0010\n",
            "Epoch 15/60\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 262ms/step - accuracy: 0.9146 - loss: 0.2397 - val_accuracy: 0.8200 - val_loss: 0.6553 - learning_rate: 0.0010\n",
            "Epoch 16/60\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 314ms/step - accuracy: 0.9275 - loss: 0.2280 - val_accuracy: 0.8400 - val_loss: 0.5366 - learning_rate: 0.0010\n",
            "Epoch 17/60\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 264ms/step - accuracy: 0.9318 - loss: 0.2316 - val_accuracy: 0.9000 - val_loss: 0.5012 - learning_rate: 0.0010\n",
            "Epoch 18/60\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 266ms/step - accuracy: 0.8543 - loss: 0.4455 - val_accuracy: 0.8700 - val_loss: 0.3501 - learning_rate: 0.0010\n",
            "Epoch 19/60\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 271ms/step - accuracy: 0.9223 - loss: 0.2508 - val_accuracy: 0.9200 - val_loss: 0.3188 - learning_rate: 0.0010\n",
            "Epoch 20/60\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 262ms/step - accuracy: 0.9567 - loss: 0.1492 - val_accuracy: 0.9600 - val_loss: 0.1501 - learning_rate: 0.0010\n",
            "Epoch 21/60\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 278ms/step - accuracy: 0.9731 - loss: 0.1113 - val_accuracy: 0.9300 - val_loss: 0.2697 - learning_rate: 0.0010\n",
            "Epoch 22/60\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 256ms/step - accuracy: 0.9768 - loss: 0.0844 - val_accuracy: 0.8700 - val_loss: 0.6064 - learning_rate: 0.0010\n",
            "Epoch 23/60\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 271ms/step - accuracy: 0.9347 - loss: 0.1997 - val_accuracy: 0.9000 - val_loss: 0.5051 - learning_rate: 0.0010\n",
            "Epoch 24/60\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 258ms/step - accuracy: 0.9560 - loss: 0.1902 - val_accuracy: 0.8900 - val_loss: 0.3034 - learning_rate: 0.0010\n",
            "Epoch 25/60\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 276ms/step - accuracy: 0.9506 - loss: 0.1565 - val_accuracy: 0.9100 - val_loss: 0.2537 - learning_rate: 0.0010\n",
            "Epoch 26/60\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 254ms/step - accuracy: 0.9817 - loss: 0.0671 - val_accuracy: 0.9200 - val_loss: 0.2617 - learning_rate: 5.0000e-04\n",
            "Epoch 27/60\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 303ms/step - accuracy: 0.9917 - loss: 0.0392 - val_accuracy: 0.9300 - val_loss: 0.2544 - learning_rate: 5.0000e-04\n",
            "Epoch 28/60\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 236ms/step - accuracy: 0.9933 - loss: 0.0328 - val_accuracy: 0.9500 - val_loss: 0.1765 - learning_rate: 5.0000e-04\n",
            "Epoch 29/60\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 306ms/step - accuracy: 0.9956 - loss: 0.0264 - val_accuracy: 0.9400 - val_loss: 0.2886 - learning_rate: 5.0000e-04\n",
            "Epoch 30/60\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 239ms/step - accuracy: 0.9976 - loss: 0.0257 - val_accuracy: 0.9700 - val_loss: 0.1230 - learning_rate: 5.0000e-04\n",
            "Epoch 31/60\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 303ms/step - accuracy: 0.9864 - loss: 0.0330 - val_accuracy: 0.9400 - val_loss: 0.2761 - learning_rate: 5.0000e-04\n",
            "Epoch 32/60\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 234ms/step - accuracy: 0.9982 - loss: 0.0177 - val_accuracy: 0.9400 - val_loss: 0.2625 - learning_rate: 5.0000e-04\n",
            "Epoch 33/60\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 305ms/step - accuracy: 0.9922 - loss: 0.0199 - val_accuracy: 0.9500 - val_loss: 0.2435 - learning_rate: 5.0000e-04\n",
            "Epoch 34/60\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 240ms/step - accuracy: 0.9882 - loss: 0.0600 - val_accuracy: 0.9500 - val_loss: 0.3692 - learning_rate: 5.0000e-04\n",
            "Epoch 35/60\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 301ms/step - accuracy: 0.9878 - loss: 0.0852 - val_accuracy: 0.8800 - val_loss: 0.5276 - learning_rate: 5.0000e-04\n",
            "Epoch 36/60\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 236ms/step - accuracy: 0.9862 - loss: 0.0634 - val_accuracy: 0.9300 - val_loss: 0.2766 - learning_rate: 2.5000e-04\n",
            "Epoch 37/60\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 237ms/step - accuracy: 0.9942 - loss: 0.0316 - val_accuracy: 0.9200 - val_loss: 0.2082 - learning_rate: 2.5000e-04\n",
            "Epoch 38/60\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 308ms/step - accuracy: 0.9940 - loss: 0.0212 - val_accuracy: 0.9200 - val_loss: 0.2618 - learning_rate: 2.5000e-04\n",
            "Epoch 39/60\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 239ms/step - accuracy: 0.9950 - loss: 0.0155 - val_accuracy: 0.9200 - val_loss: 0.2625 - learning_rate: 2.5000e-04\n",
            "Epoch 40/60\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 301ms/step - accuracy: 0.9989 - loss: 0.0146 - val_accuracy: 0.9200 - val_loss: 0.2530 - learning_rate: 2.5000e-04\n",
            "✅ Test accuracy (Day_1–8 → Day_10): 0.8989899158477783\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 8 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7eb8dae756c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7eb8dae756c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=h5\n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ada     1.0000    0.5000    0.6667        10\n",
            "   awidinawa     0.9000    0.9000    0.9000        10\n",
            "        boru     1.0000    0.9000    0.9474        10\n",
            "      hawasa     1.0000    1.0000    1.0000        10\n",
            "       hodai     0.7143    1.0000    0.8333        10\n",
            "       irida     1.0000    1.0000    1.0000         9\n",
            "     narakai     0.9091    1.0000    0.9524        10\n",
            "        pata     0.7692    1.0000    0.8696        10\n",
            "      saduda     0.9091    1.0000    0.9524        10\n",
            "     udasana     1.0000    0.7000    0.8235        10\n",
            "\n",
            "    accuracy                         0.8990        99\n",
            "   macro avg     0.9202    0.9000    0.8945        99\n",
            "weighted avg     0.9194    0.8990    0.8935        99\n",
            "\n",
            "\n",
            "Confusion matrix (rows=true, cols=pred):\n",
            "[[ 5  1  0  0  4  0  0  0  0  0]\n",
            " [ 0  9  0  0  0  0  1  0  0  0]\n",
            " [ 0  0  9  0  0  0  0  0  1  0]\n",
            " [ 0  0  0 10  0  0  0  0  0  0]\n",
            " [ 0  0  0  0 10  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  9  0  0  0  0]\n",
            " [ 0  0  0  0  0  0 10  0  0  0]\n",
            " [ 0  0  0  0  0  0  0 10  0  0]\n",
            " [ 0  0  0  0  0  0  0  0 10  0]\n",
            " [ 0  0  0  0  0  0  0  3  0  7]]\n",
            "Saved cnn_lstm_baseline.h5\n",
            "Saved artifact at '/content/cnn_lstm_savedmodel'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 512, 9), dtype=tf.float32, name='keras_tensor_73')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 10), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  139332876736592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139332876741392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139332876738128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139332876739664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139332876739856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139332876742160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139332876739472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139332876737744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139332876736784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139332876744080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139332876737360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139332876743312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139332876743120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139332876746000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139332876744656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139332845125904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139332845126096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139332845125712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139332845127824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "Saved SavedModel to /content/cnn_lstm_savedmodel\n",
            "  adding: content/cnn_lstm_savedmodel/ (stored 0%)\n",
            "  adding: content/cnn_lstm_savedmodel/saved_model.pb (deflated 86%)\n",
            "  adding: content/cnn_lstm_savedmodel/variables/ (stored 0%)\n",
            "  adding: content/cnn_lstm_savedmodel/variables/variables.data-00000-of-00001 (deflated 8%)\n",
            "  adding: content/cnn_lstm_savedmodel/variables/variables.index (deflated 68%)\n",
            "  adding: content/cnn_lstm_savedmodel/assets/ (stored 0%)\n",
            "  adding: content/cnn_lstm_savedmodel/fingerprint.pb (stored 0%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save as TensorFlow SavedModel (folder)\n",
        "model.export(\"/content/cnn_lstm_savedmodel\")\n",
        "print(\"Saved SavedModel to /content/cnn_lstm_savedmodel\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N2gjdht-EB0f",
        "outputId": "70724dae-8ec9-471e-a609-2e1e96f053ac"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved artifact at '/content/cnn_lstm_savedmodel'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 512, 9), dtype=tf.float32, name='keras_tensor_30')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 10), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  139333017091344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139333017091152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139332880254160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139332880254352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139333017091728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139333017091536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139332880253008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139332880253584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139332880253968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139332880255504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139332880255312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139332880253776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139332880256080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139332865395792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139332880257040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139332880255120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139332880256656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139332880257424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139332880258192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "Saved SavedModel to /content/cnn_lstm_savedmodel\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r cnn_lstm_savedmodel.zip /content/cnn_lstm_savedmodel\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BS3LurpTQN0L",
        "outputId": "ceb6bfcc-f206-4200-fe5f-e34f8355d1e6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/cnn_lstm_savedmodel/ (stored 0%)\n",
            "  adding: content/cnn_lstm_savedmodel/saved_model.pb (deflated 86%)\n",
            "  adding: content/cnn_lstm_savedmodel/variables/ (stored 0%)\n",
            "  adding: content/cnn_lstm_savedmodel/variables/variables.data-00000-of-00001 (deflated 8%)\n",
            "  adding: content/cnn_lstm_savedmodel/variables/variables.index (deflated 68%)\n",
            "  adding: content/cnn_lstm_savedmodel/assets/ (stored 0%)\n",
            "  adding: content/cnn_lstm_savedmodel/fingerprint.pb (stored 0%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m = tf.keras.models.load_model(\"/content/cnn_lstm_best.keras\", compile=False)\n",
        "m.export(\"/content/cnn_lstm_savedmodel\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBXoKZVSQ2nK",
        "outputId": "ff0c1c3d-ffce-4af9-adbe-4b9710dd6d59"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved artifact at '/content/cnn_lstm_savedmodel'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): List[TensorSpec(shape=(None, 512, 9), dtype=tf.float32, name='input_layer')]\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 10), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  139332880260304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139332880262416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139332880260880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139332880256848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139332880254544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139332880260496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139332880259152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139332876746576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139332876737552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139332876745424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139332876745616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139332876738896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139332876746384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139332876746192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139332876744464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139332876740432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139332876742544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139332876743696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139332876742928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
          ]
        }
      ]
    }
  ]
}
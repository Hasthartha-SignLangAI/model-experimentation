{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jj4PofAL7WDa",
        "outputId": "ca647ffc-3bcd-4572-c130-25fc5d4f6f36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset root: /content/v2\n",
            "Total files found: 1000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:08<00:00, 116.81it/s]\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded samples: 722\n",
            "Data shape: (722, 200, 9)\n",
            "Classes: ['ada' 'awidinawa' 'boru' 'hawasa' 'hodai' 'irida' 'narakai' 'pata'\n",
            " 'saduda' 'udasana']\n",
            "Train: (505, 200, 9)\n",
            "Val: (108, 200, 9)\n",
            "Test: (109, 200, 9)\n",
            "\n",
            "Training CNN model...\n",
            "Epoch 1/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - accuracy: 0.1648 - loss: 2.2767 - val_accuracy: 0.3241 - val_loss: 2.0374\n",
            "Epoch 2/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.3511 - loss: 1.9632 - val_accuracy: 0.3889 - val_loss: 1.7004\n",
            "Epoch 3/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.3950 - loss: 1.6515 - val_accuracy: 0.4259 - val_loss: 1.6026\n",
            "Epoch 4/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.4373 - loss: 1.5277 - val_accuracy: 0.4722 - val_loss: 1.5360\n",
            "Epoch 5/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.5066 - loss: 1.3666 - val_accuracy: 0.5370 - val_loss: 1.5018\n",
            "Epoch 6/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.5163 - loss: 1.3592 - val_accuracy: 0.5370 - val_loss: 1.4147\n",
            "Epoch 7/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.5893 - loss: 1.1833 - val_accuracy: 0.5370 - val_loss: 1.3121\n",
            "Epoch 8/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.6041 - loss: 1.1004 - val_accuracy: 0.6111 - val_loss: 1.2587\n",
            "Epoch 9/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.6326 - loss: 1.0415 - val_accuracy: 0.5741 - val_loss: 1.2862\n",
            "Epoch 10/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.6270 - loss: 0.9725 - val_accuracy: 0.5741 - val_loss: 1.2200\n",
            "Epoch 11/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.6924 - loss: 0.8721 - val_accuracy: 0.5926 - val_loss: 1.2718\n",
            "Epoch 12/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.6672 - loss: 0.9047 - val_accuracy: 0.6111 - val_loss: 1.2404\n",
            "Epoch 13/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.6922 - loss: 0.8437 - val_accuracy: 0.6204 - val_loss: 1.1706\n",
            "Epoch 14/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.6845 - loss: 0.8095 - val_accuracy: 0.6389 - val_loss: 1.2000\n",
            "Epoch 15/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.7141 - loss: 0.7499 - val_accuracy: 0.6296 - val_loss: 1.1985\n",
            "Epoch 16/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.7061 - loss: 0.7824 - val_accuracy: 0.6204 - val_loss: 1.2082\n",
            "Epoch 17/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.7277 - loss: 0.7708 - val_accuracy: 0.6759 - val_loss: 1.1597\n",
            "Epoch 18/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.7506 - loss: 0.6417 - val_accuracy: 0.6759 - val_loss: 1.2257\n",
            "Epoch 19/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.7676 - loss: 0.6537 - val_accuracy: 0.6759 - val_loss: 1.0823\n",
            "Epoch 20/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.7599 - loss: 0.6183 - val_accuracy: 0.6667 - val_loss: 1.1845\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "CNN Accuracy: 0.6697247706422018\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.41      0.75      0.53        12\n",
            "           1       0.62      0.67      0.64        12\n",
            "           2       1.00      0.55      0.71        11\n",
            "           3       0.80      0.36      0.50        11\n",
            "           4       0.89      0.67      0.76        12\n",
            "           5       0.62      0.62      0.62         8\n",
            "           6       0.56      0.56      0.56         9\n",
            "           7       0.92      1.00      0.96        11\n",
            "           8       0.80      0.67      0.73        12\n",
            "           9       0.60      0.82      0.69        11\n",
            "\n",
            "    accuracy                           0.67       109\n",
            "   macro avg       0.72      0.67      0.67       109\n",
            "weighted avg       0.73      0.67      0.67       109\n",
            "\n",
            "\n",
            "Training LSTM model...\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 496ms/step - accuracy: 0.1914 - loss: 2.2378 - val_accuracy: 0.3241 - val_loss: 1.9185\n",
            "Epoch 2/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 543ms/step - accuracy: 0.3563 - loss: 1.8084 - val_accuracy: 0.3704 - val_loss: 1.7293\n",
            "Epoch 3/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 542ms/step - accuracy: 0.4434 - loss: 1.5343 - val_accuracy: 0.3981 - val_loss: 1.6009\n",
            "Epoch 4/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 483ms/step - accuracy: 0.5041 - loss: 1.3691 - val_accuracy: 0.4444 - val_loss: 1.5941\n",
            "Epoch 5/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 537ms/step - accuracy: 0.5273 - loss: 1.2526 - val_accuracy: 0.4815 - val_loss: 1.4775\n",
            "Epoch 6/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 539ms/step - accuracy: 0.5936 - loss: 1.1640 - val_accuracy: 0.5370 - val_loss: 1.3743\n",
            "Epoch 7/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 468ms/step - accuracy: 0.6252 - loss: 1.0461 - val_accuracy: 0.5370 - val_loss: 1.3841\n",
            "Epoch 8/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 547ms/step - accuracy: 0.6694 - loss: 0.9376 - val_accuracy: 0.4815 - val_loss: 1.5293\n",
            "Epoch 9/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 546ms/step - accuracy: 0.5948 - loss: 1.0853 - val_accuracy: 0.5093 - val_loss: 1.4037\n",
            "Epoch 10/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 512ms/step - accuracy: 0.6572 - loss: 0.9197 - val_accuracy: 0.5370 - val_loss: 1.4572\n",
            "Epoch 11/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 465ms/step - accuracy: 0.7662 - loss: 0.7253 - val_accuracy: 0.5648 - val_loss: 1.5284\n",
            "Epoch 12/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 546ms/step - accuracy: 0.7569 - loss: 0.7032 - val_accuracy: 0.5556 - val_loss: 1.6162\n",
            "Epoch 13/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 550ms/step - accuracy: 0.7668 - loss: 0.7288 - val_accuracy: 0.5741 - val_loss: 1.3801\n",
            "Epoch 14/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 464ms/step - accuracy: 0.7611 - loss: 0.6602 - val_accuracy: 0.5926 - val_loss: 1.4691\n",
            "Epoch 15/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 461ms/step - accuracy: 0.7472 - loss: 0.6987 - val_accuracy: 0.5556 - val_loss: 1.5717\n",
            "Epoch 16/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 544ms/step - accuracy: 0.7669 - loss: 0.6218 - val_accuracy: 0.5833 - val_loss: 1.4571\n",
            "Epoch 17/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 525ms/step - accuracy: 0.8346 - loss: 0.5119 - val_accuracy: 0.5648 - val_loss: 1.5780\n",
            "Epoch 18/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 474ms/step - accuracy: 0.8497 - loss: 0.4520 - val_accuracy: 0.6019 - val_loss: 1.7040\n",
            "Epoch 19/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 547ms/step - accuracy: 0.8635 - loss: 0.4382 - val_accuracy: 0.5926 - val_loss: 1.5408\n",
            "Epoch 20/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 547ms/step - accuracy: 0.8226 - loss: 0.4876 - val_accuracy: 0.5463 - val_loss: 1.6092\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 233ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "LSTM Accuracy: 0.6146788990825688\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.58      0.54        12\n",
            "           1       0.67      0.50      0.57        12\n",
            "           2       0.73      0.73      0.73        11\n",
            "           3       0.36      0.36      0.36        11\n",
            "           4       0.78      0.58      0.67        12\n",
            "           5       1.00      0.62      0.77         8\n",
            "           6       0.45      0.56      0.50         9\n",
            "           7       0.90      0.82      0.86        11\n",
            "           8       0.70      0.58      0.64        12\n",
            "           9       0.47      0.82      0.60        11\n",
            "\n",
            "    accuracy                           0.61       109\n",
            "   macro avg       0.66      0.62      0.62       109\n",
            "weighted avg       0.65      0.61      0.62       109\n",
            "\n",
            "\n",
            "==============================\n",
            "FINAL ACCURACY COMPARISON\n",
            "==============================\n",
            "CNN  : 0.6697247706422018\n",
            "LSTM : 0.6146788990825688\n",
            "==============================\n"
          ]
        }
      ],
      "source": [
        "# =========================================================\n",
        "#  EMG + IMU Gesture Training Pipeline\n",
        "#  CNN vs LSTM (Research Comparison)\n",
        "#  FULL CLEAN VERSION — NO PATCHING REQUIRED\n",
        "# =========================================================\n",
        "\n",
        "!pip install -q tensorflow scikit-learn joblib tqdm\n",
        "\n",
        "import os, zipfile, glob, joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# =========================================================\n",
        "# CONFIG\n",
        "# =========================================================\n",
        "\n",
        "DATASET_ZIP = \"/content/v2.zip\"   # upload your zip here\n",
        "EXTRACT_DIR = \"/content\"\n",
        "DATASET_DIR = \"/content/v2\"\n",
        "\n",
        "SEQ_LEN = 200\n",
        "FEATURES = [\"emg1\",\"emg2\",\"emg3\",\"ax\",\"ay\",\"az\",\"gx\",\"gy\",\"gz\"]\n",
        "\n",
        "# =========================================================\n",
        "# EXTRACT DATASET\n",
        "# =========================================================\n",
        "\n",
        "if not os.path.exists(DATASET_DIR):\n",
        "    with zipfile.ZipFile(DATASET_ZIP, 'r') as z:\n",
        "        z.extractall(EXTRACT_DIR)\n",
        "\n",
        "print(\"Dataset root:\", DATASET_DIR)\n",
        "\n",
        "# =========================================================\n",
        "# PAD FUNCTION\n",
        "# =========================================================\n",
        "\n",
        "def pad_sequence(x):\n",
        "    if len(x) > SEQ_LEN:\n",
        "        return x[:SEQ_LEN]\n",
        "    pad = np.zeros((SEQ_LEN-len(x), x.shape[1]))\n",
        "    return np.vstack([x, pad])\n",
        "\n",
        "# =========================================================\n",
        "# LOAD DATA (ROBUST VERSION)\n",
        "# =========================================================\n",
        "\n",
        "X, y = [], []\n",
        "\n",
        "files = glob.glob(DATASET_DIR + \"/*/*/*.txt\")\n",
        "print(\"Total files found:\", len(files))\n",
        "\n",
        "for file in tqdm(files):\n",
        "\n",
        "    try:\n",
        "        # auto detect separator (comma/space/tab)\n",
        "        df = pd.read_csv(file, sep=None, engine=\"python\")\n",
        "\n",
        "        # skip broken files\n",
        "        if df.shape[1] < 10:\n",
        "            continue\n",
        "\n",
        "        # assign columns\n",
        "        df.columns = [\"t\",\"emg1\",\"emg2\",\"emg3\",\"ax\",\"ay\",\"az\",\"gx\",\"gy\",\"gz\"]\n",
        "\n",
        "        seq = pad_sequence(df[FEATURES].values)\n",
        "\n",
        "        gesture = file.split(\"/\")[-3]   # folder name is label\n",
        "\n",
        "        X.append(seq)\n",
        "        y.append(gesture)\n",
        "\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "print(\"Loaded samples:\", len(X))\n",
        "print(\"Data shape:\", X.shape)\n",
        "\n",
        "assert len(X) > 0, \"❌ No samples loaded. Check dataset path or format.\"\n",
        "\n",
        "# =========================================================\n",
        "# NORMALIZE\n",
        "# =========================================================\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "X_2d = X.reshape(-1, X.shape[-1])\n",
        "X_2d = scaler.fit_transform(X_2d)\n",
        "X = X_2d.reshape(X.shape)\n",
        "\n",
        "joblib.dump(scaler, \"scaler.pkl\")\n",
        "\n",
        "# =========================================================\n",
        "# ENCODE LABELS\n",
        "# =========================================================\n",
        "\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)\n",
        "\n",
        "joblib.dump(le, \"label_map.pkl\")\n",
        "\n",
        "print(\"Classes:\", le.classes_)\n",
        "\n",
        "# =========================================================\n",
        "# SPLIT\n",
        "# =========================================================\n",
        "\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "    X, y, test_size=0.3, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "X_val, X_test, y_val, y_test = train_test_split(\n",
        "    X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42\n",
        ")\n",
        "\n",
        "print(\"Train:\", X_train.shape)\n",
        "print(\"Val:\", X_val.shape)\n",
        "print(\"Test:\", X_test.shape)\n",
        "\n",
        "# =========================================================\n",
        "# ================= CNN MODEL =============================\n",
        "# =========================================================\n",
        "\n",
        "cnn_model = models.Sequential([\n",
        "    layers.Conv1D(64,3,activation='relu',input_shape=(SEQ_LEN,9)),\n",
        "    layers.MaxPooling1D(2),\n",
        "\n",
        "    layers.Conv1D(128,3,activation='relu'),\n",
        "    layers.MaxPooling1D(2),\n",
        "\n",
        "    layers.Conv1D(256,3,activation='relu'),\n",
        "    layers.GlobalAveragePooling1D(),\n",
        "\n",
        "    layers.Dense(128,activation='relu'),\n",
        "    layers.Dropout(0.3),\n",
        "    layers.Dense(len(le.classes_),activation='softmax')\n",
        "])\n",
        "\n",
        "cnn_model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "print(\"\\nTraining CNN model...\")\n",
        "cnn_model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=20,\n",
        "    batch_size=32,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "cnn_pred = np.argmax(cnn_model.predict(X_test), axis=1)\n",
        "cnn_acc = accuracy_score(y_test, cnn_pred)\n",
        "\n",
        "print(\"\\nCNN Accuracy:\", cnn_acc)\n",
        "print(classification_report(y_test, cnn_pred))\n",
        "\n",
        "cnn_model.save(\"cnn_model.h5\")\n",
        "\n",
        "\n",
        "# =========================================================\n",
        "# ================= LSTM MODEL ============================\n",
        "# =========================================================\n",
        "\n",
        "lstm_model = models.Sequential([\n",
        "    layers.LSTM(128, return_sequences=True, input_shape=(SEQ_LEN,9)),\n",
        "    layers.Dropout(0.3),\n",
        "\n",
        "    layers.LSTM(128),\n",
        "    layers.Dropout(0.3),\n",
        "\n",
        "    layers.Dense(128,activation='relu'),\n",
        "    layers.Dense(len(le.classes_),activation='softmax')\n",
        "])\n",
        "\n",
        "lstm_model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "print(\"\\nTraining LSTM model...\")\n",
        "lstm_model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=20,\n",
        "    batch_size=32,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "lstm_pred = np.argmax(lstm_model.predict(X_test), axis=1)\n",
        "lstm_acc = accuracy_score(y_test, lstm_pred)\n",
        "\n",
        "print(\"\\nLSTM Accuracy:\", lstm_acc)\n",
        "print(classification_report(y_test, lstm_pred))\n",
        "\n",
        "lstm_model.save(\"lstm_model.h5\")\n",
        "\n",
        "\n",
        "# =========================================================\n",
        "# FINAL COMPARISON\n",
        "# =========================================================\n",
        "\n",
        "print(\"\\n==============================\")\n",
        "print(\"FINAL ACCURACY COMPARISON\")\n",
        "print(\"==============================\")\n",
        "print(\"CNN  :\", cnn_acc)\n",
        "print(\"LSTM :\", lstm_acc)\n",
        "print(\"==============================\")\n"
      ]
    }
  ]
}